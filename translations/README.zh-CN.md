## 通信协议

架构风格阐明了应用程序编程接口（API）中不同组件之间的相互作用。因此，通过提供标准的方法来设计和构建API，以确保与其他系统的高效、可靠和易集成性。以下是最常用的风格：

<p> <img src="images/api-architecture-styles.png" style="width: 640px"> </p>

- SOAP：

  成熟、全面、基于XML

  最适用于企业应用

- RESTful：

  流行、易于实现、HTTP方法

  理想用于Web服务

- GraphQL：

  查询语言，请求特定数据

  减少网络开销，响应更快

- gRPC：

  现代、高性能、协议缓冲区

  适用于微服务架构

- WebSocket：

  实时、双向、持久连接

  非常适合低延迟的数据交换

- Webhook：

  事件驱动、HTTP回调、异步

  当事件发生时通知系统


### REST API与GraphQL的比较

在API设计方面，REST和GraphQL各有其长处与不足。

下图展示了REST和GraphQL之间的快速比较。

<p> <img src="images/graphQL.jpg"> </p>

REST

- 使用标准HTTP方法，如GET、POST、PUT、DELETE进行CRUD操作。
- 当需要简单、统一的接口在不同服务/应用之间时工作良好。
- 缓存策略简单易于实施。
- 缺点是可能需要多次往返请求来组装来自不同端点的相关数据。

GraphQL

- 提供一个单一的端点，供客户端精确查询所需的数据。
- 客户端在嵌套查询中指定所需的确切字段，服务器返回仅包含这些字段的优化数据包。
- 支持用于修改数据的变更（Mutations）和用于实时通知的订阅（Subscriptions）。
- 非常适合从多个来源汇总数据，并与快速发展的前端需求相处良好。
- 然而，它将复杂性转移到客户端，如果没有妥善保护，可能导致查询滥用 - 缓存策略可能比REST更复杂。

在REST和GraphQL之间的最佳选择取决于应用程序和开发团队的具体需求。对于复杂或经常变化的前端需求，GraphQL是一个不错的选择，而REST适用于更简单和一致的契约应用。

这两种API方法都不是灵丹妙药。仔细评估需求和权衡是选择合适风格的重要因素。REST和GraphQL都是有效的选项，用于暴露数据和驱动现代应用程序。


### gRPC是如何工作的？

RPC（远程过程调用）之所以称为“**远程**”，是因为它在微服务架构中允许部署在不同服务器上的远程服务之间进行通信。从用户的角度来看，它就像本地函数调用一样。

下图说明了**gRPC**的整体数据流。

<p> <img src="images/grpc.jpg"> </p>

步骤1：从客户端发起REST调用。请求体通常为JSON格式。

步骤2 - 4：订单服务（gRPC客户端）接收REST调用，转换并向支付服务发起RPC调用。gRPC将**客户端存根**编码为二进制格式，并将其发送到底层传输层。

步骤5：gRPC通过HTTP2将数据包发送到网络。由于二进制编码和网络优化，gRPC被认为比JSON快5倍。

步骤6 - 8：支付服务（gRPC服务器）从网络中接收数据包，解码它们并调用服务器应用。

步骤9 - 11：结果从服务器应用返回，并被编码并发送到传输层。

步骤12 - 14：订单服务接收数据包，解码它们，并将结果发送给客户端应用。

### 什么是Webhook？

下图显示了轮询和Webhook之间的比较。

<p> <img src="images/webhook.jpeg" style="width: 680px" /> </p>

假设我们运营一个电子商务网站。客户通过API网关将订单发送到订单服务，然后转到支付服务进行支付交易。支付服务随后与外部支付服务提供商（PSP）对接，以完成交易。

有两种方法可以处理与外部PSP的通信。

**1. 短轮询**

在向PSP发送支付请求后，支付服务不断询问PSP支付状态。在几轮询问后，PSP最终返回状态。

短轮询有两个缺点：
* 持续轮询状态需要支付服务的资源。
* 外部服务直接与支付服务通信，造成安全漏洞。

**2. Webhook**

我们可以在外部服务上注册一个Webhook。这意味着：当你对请求有更新时，在特定的URL上回调通知我们。当PSP完成处理后，它将调用HTTP请求来更新支付状态。

通过这种方式，编程范式发生了改变，支付服务不再需要浪费资源去轮询支付状态。

如果PSP从未回调怎么办？我们可以设置每小时定期检查支付状态的任务。

Webhook通常被称为反向API或推送API，因为服务器向客户端发送HTTP请求。我们在使用Webhook时需要注意三件事：

1. 我们需要为外部服务设计一个合适的API供其调用。
2. 我们需要在API网关中设置合适的规则以确保安全。
3. 我们需要在外部服务上注册正确的URL。

### 如何提高API性能？

下图展示了改善API性能的五个常见技巧。

<p> <img src="images/api-performance.jpg"> </p>

分页

这是在结果集较大时常见的优化。结果会流式返回给客户端，以提高服务响应能力。

异步日志记录

同步日志记录对于每个调用都要处理磁盘，这可能会降低系统速度。异步日志记录首先将日志发送到无锁缓冲区，并立即返回。日志将周期性地刷新到磁盘。这显著减少了I/O开销。

缓存

我们可以将频繁访问的数据存储在缓存中。客户端可以首先查询缓存，而不是直接访问数据库。如果缓存未命中，客户端可以查询数据库。像Redis这样的缓存将数据存储在内存中，因此数据访问速度远快于数据库。

负载压缩

请求和响应可以使用gzip等进行压缩，从而传输的数据大小大幅减少。这加快了上传和下载速度。

连接池

在访问资源时，我们通常需要从数据库中加载数据。打开和关闭数据库连接会增加显著的开销。因此，我们应该通过打开连接的池与数据库进行连接。连接池负责管理连接生命周期。

### HTTP 1.0 -> HTTP 1.1 -> HTTP 2.0 -> HTTP 3.0 (QUIC)

每一代HTTP解决了什么问题？

下图说明了关键特性。

<p> <img src="images/http3.jpg" /> </p>

- HTTP 1.0于1996年最终确定并完整记录。每次对同一服务器的请求都需要单独的TCP连接。

- HTTP 1.1于1997年发布。TCP连接可以保持打开以供重用（持久连接），但未解决HOL（头阻塞）问题。

  HOL阻塞 - 当浏览器中允许的并行请求数量用尽时，后续请求需要等待前面的请求完成。

- HTTP 2.0于2015年发布。它通过请求复用解决了HOL问题，消除了应用层的HOL阻塞，但在传输（TCP）层仍然存在HOL。

  如图所示，HTTP 2.0引入了HTTP“流”的概念：一种将不同HTTP交换复用到同一TCP连接的抽象。每个流不需要按顺序发送。

- HTTP 3.0的首次草稿于2020年发布。它是HTTP 2.0的拟议继任者。它使用QUIC而不是TCP作为基础传输协议，从而消除了传输层的HOL阻塞。

QUIC基于UDP。它在传输层引入了流作为一等公民。QUIC流共享同一个QUIC连接，因此不需要额外的握手和慢启动来创建新的流，但QUIC流是独立传输的，在大多数情况下，影响一个流的丢包不会影响其他流。

### SOAP vs REST vs GraphQL vs RPC

下图展示了API发展时间线和API风格的比较。

随着时间的推移，不同的API架构风格被发布。每种风格都有其标准化数据交换的模式。

你可以在图中查看每种风格的用例。

<p> <img src="images/SOAP vs REST vs GraphQL vs RPC.jpeg" /> </p>

### 代码优先与API优先 

下面的图表展示了代码优先开发与API优先开发之间的区别。我们为什么要考虑API优先设计？

<p> <img src="images/api_first.jpg" style="width: 680px" /> </p>

- 微服务增加了系统复杂性，我们有多个微服务来处理系统不同的功能。虽然这种架构便于解耦和职责分离，但我们需要处理服务之间的各种通信。

在编写代码之前，考虑系统的复杂性并仔细定义服务的边界是最佳实践。

- 不同的职能团队需要讲同一种语言，而专门的职能团队只需对自己的组件和服务负责。建议组织通过API设计讲同一种语言。

我们可以通过模拟请求和响应来验证API设计，然后再编写代码。

- API优先设计提高了软件质量和开发者生产力。由于在项目开始时我们已经理清了大部分的不确定性，因此整体开发过程更加顺畅，软件质量得到了极大提高。

开发者们也对这个过程更加满意，因为他们可以专注于功能开发，而不是处理突发的变更。

在项目生命周期结束时出现意外的可能性降低。

由于采用API优先设计，测试可以在代码开发的同时进行。在某种程度上，我们在使用API优先开发时也有测试驱动设计（TDD）。

### HTTP状态码

<p> <img src="images/http-status-code.jpg" style="width: 540px" /> </p>

HTTP的响应代码分为五类：

信息性（100-199）  
成功（200-299）  
重定向（300-399）  
客户端错误（400-499）  
服务器错误（500-599）  

### API网关的作用是什么？

下面的图表展示了相关细节。

<p> <img src="images/api_gateway.jpg" style="width: 520px" /> </p>

第1步 - 客户端向API网关发送HTTP请求。

第2步 - API网关解析并验证HTTP请求中的属性。

第3步 - API网关执行允许列表/拒绝列表检查。

第4步 - API网关与身份提供者进行身份验证和授权。

第5步 - 请求应用速率限制规则。如果超出限制，请求将被拒绝。

第6和第7步 - 现在请求已经通过基本检查，API网关通过路径匹配找到相关服务进行路由。

第8步 - API网关将请求转换为适当的协议，并将其发送到后端微服务。

第9到第12步：API网关可以正确处理错误，并在错误恢复需要更长时间时处理故障（电路断路器）。它还可以利用ELK（Elastic-Logstash-Kibana）堆栈用于日志记录和监控。我们有时会在API网关中缓存数据。

### 我们如何设计有效和安全的API？

下面的图表展示了使用购物车示例的典型API设计。

<p> <img src="images/safe-apis.jpg" /> </p>

请注意，API设计不仅仅是URL路径设计。大多数情况下，我们需要选择合适的资源名称、标识符和路径模式。设计合适的HTTP头字段或在API网关中设计有效的速率限制规则同样重要。

### TCP/IP封装 

数据是如何通过网络发送的？为什么在OSI模型中需要这么多层？

下面的图表展示了数据在网络上传输时的封装和解封装过程。

<p> <img src="images/osi model.jpeg" /> </p>

第1步：当设备A通过HTTP协议向设备B发送数据时，首先在应用层添加一个HTTP头。

第2步：然后在数据上添加TCP或UDP头。数据在传输层封装为TCP段。头部包含源端口、目标端口和序列号。

第3步：然后在网络层将段封装为IP头。IP头中包含源/目标IP地址。

第4步：在数据链路层，IP数据报文添加一个MAC头，包括源/目标MAC地址。

第5步：封装过的帧被发送到物理层，并以二进制位的形式通过网络发送。

步骤6-10：当设备B从网络接收位时，它执行去封装过程，这是一种封装过程的逆向处理。头部逐层被移除，最终，设备B可以读取数据。

我们在网络模型中需要分层，因为每一层关注自身的责任。每一层可以依赖于头部的处理指令，而无需知晓来自上一层数据的意义。

### 为什么Nginx被称为“反向”代理？

下图显示了转发代理和反向代理之间的区别。

<p> <img src="images/Forward Proxy v.s. Reverse Proxy2x.jpg" style="width: 720px" /> </p>

转发代理是一个位于用户设备与互联网之间的服务器。

转发代理通常用于：

1. 保护客户端
2. 规避浏览限制
3. 阻止访问某些内容

反向代理是一个接受客户端请求的服务器，它将请求转发到Web服务器，并将结果返回给客户端，就好像代理服务器处理了请求一样。

反向代理常用于：

1. 保护服务器
2. 负载均衡
3. 缓存静态内容
4. 加密和解密SSL通信

### 常见的负载均衡算法有哪些？

下图显示了6种常见的算法。

<p> <img src="images/lb-algorithms.jpg" /> </p>

- 静态算法

1. 轮询

    客户端请求按顺序发送到不同的服务实例。通常要求服务是无状态的。

3. 粘性轮询算法

    这是轮询算法的改进。如果艾丽丝的第一次请求发送到服务A，后续请求也发送到服务A。

4. 加权轮询

    管理员可以为每个服务指定权重。权重更高的服务处理的请求比其他服务更多。

6. 哈希

    此算法在传入请求的IP或URL上应用哈希函数。根据哈希函数的结果将请求路由到相关实例。

- 动态算法

5. 最少连接数

    新请求发送到拥有最少并发连接的服务实例。

7. 最小响应时间

    新请求发送到响应时间最快的服务实例。

### URL、URI、URN - 你知道它们之间的区别吗？

下图显示了URL、URI和URN的比较。

<p> <img src="images/url-uri-urn.jpg" /> </p>

- URI

URI代表统一资源标识符。它标识Web上的逻辑或物理资源。URL和URN是URI的子类型。URL用于定位资源，而URN则用于命名资源。

URI由以下部分组成：
scheme:[//authority]path[?query][#fragment]

- URL

URL代表统一资源定位符，是HTTP的关键概念。它是Web上唯一资源的地址。它还可以与其他协议一起使用，如FTP和JDBC。

- URN

URN代表统一资源名称。它使用urn格式。URN不能用于定位资源。图中给出的一个简单示例由命名空间和特定于命名空间的字符串组成。

如果您想了解有关该主题的更多详细信息，我建议您查看[W3C的澄清](https://www.w3.org/TR/uri-clarification/)。

## CI/CD

### CI/CD管道的简单解释

<p> <img src="images/ci-cd-pipeline.jpg" style="width: 680px" /> </p>

第1部分 - 带有CI/CD的软件开发生命周期（SDLC）

软件开发生命周期（SDLC）包含多个关键阶段：开发、测试、部署和维护。CI/CD自动化并集成这些阶段，以实现更快和更可靠的发布。

当代码提交到git仓库时，该操作会触发自动化构建和测试过程。运行E2E（端到端）测试用例以验证代码。如果测试通过，代码可以自动部署到预生产/生产环境。如果发现问题，代码将返回开发环节进行错误修复。自动化流程能快速为开发人员提供反馈，并减少了生产环境中出现错误的风险。

第二节 - CI与CD的区别

持续集成（CI）自动化构建、测试和合并过程。每当有代码提交时，它就会运行测试，以便及早发现集成问题。这鼓励频繁的代码提交和快速反馈。

持续交付（CD）自动化基础设施变更和部署等发布过程。通过自动化工作流程，确保软件可以随时可靠地发布。CD还可以自动化发布到生产环境前所需的手动测试和审批步骤。

第三节 - CI/CD流水线

一个典型的CI/CD流水线有几个连接的阶段：
- 开发者将代码更改提交到源控制 - CI服务器检测到更改并触发构建 - 代码被编译并测试（单元测试、集成测试） - 测试结果报告给开发者 - 成功时，构件部署到预生产环境 - 在发布之前，可能在预生产环境中进行进一步的测试 - CD系统将批准的更改部署到生产环境

### Netflix技术栈（CI/CD流水线）

<p> <img src="images/netflix-ci-cd.jpg" style="width: 720px" /> </p>

规划：Netflix工程团队使用JIRA进行规划，使用Confluence进行文档编制。

编码：Java是后端服务的主要编程语言，而其他语言则用于不同的用例。

构建：Gradle主要用于构建，并构建Gradle插件以支持各种用例。

打包：包和依赖项被打包到Amazon机器镜像（AMI）中以便发布。

测试：测试强调生产文化中对混沌工具构建的关注。

部署：Netflix使用自建的Spinnaker进行金丝雀发布部署。

监控：监控指标集中在Atlas中，使用Kayenta检测异常。

事件报告：事件根据优先级分配，使用PagerDuty进行事件处理。

## 架构模式

### MVC、MVP、MVVM、MVVM-C以及VIPER
这些架构模式是应用开发中最常用的模式之一，无论是在iOS还是Android平台上。开发人员引入这些模式是为了克服早期模式的局限性。那么，它们有什么不同呢？

<p> <img src="images/client arch patterns.png" style="width: 720px" /> </p>

- MVC是最古老的模式，已有近50年的历史 - 每个模式都有一个“视图”（V），负责显示内容和接收用户输入 - 大多数模式包含一个“模型”（M），用于管理业务数据 - “控制器”、“呈现器”和“视图模型”是用来调解视图和模型之间的翻译者（在VIPER模式中称为“实体”）

### 每个开发者都应该知道的18个关键设计模式

模式是对常见设计问题的可重用解决方案，从而实现更顺畅、更高效的开发过程。它们作为构建更好软件结构的蓝图。以下是一些最流行的模式：

<p> <img src="images/18-oo-patterns.png" /> </p>

<p> <img src="images/18-oo-patterns.png" /> </p>

- 抽象工厂：家庭创建者 - 创建相关元素的组。
- 建造者：乐高大师 - 逐步构建对象，将构建过程与对象外观分离。
- 原型：克隆制造者 - 创建已准备好的完整示例的副本。
- 单例：独一无二 - 只有一个实例的特殊类。
- 适配器：万能插头 - 连接不同接口的系统。
- 桥接：功能连接器 - 将对象的工作方式与其功能连接起来。
- 组合：树构建器 - 构建由简单与复杂部分组成的树状结构。
- 装饰器：定制者 - 在不改变核心的情况下为对象添加功能。
- 外观：一站式商店 - 用单一、简化的接口呈现整个系统。
- 享元：节省空间 - 高效共享小的可重用元素。
- 代理：替代演员 - 代表另一个对象，控制访问或操作。
- 请求链：请求中继 - 通过一系列对象传递请求，直至请求被处理。
- 命令：任务包装器 - 将请求转化为准备好的对象，以便执行。
- 迭代器：集合探索者 - 逐一访问集合中的元素。
- 中介者：通信中心 - 简化不同类之间的交互。
- 备忘录：时间胶囊 - 捕捉和恢复对象的状态。
- 观察者：新闻播报员 - 通知类关于其他对象的变化。
- 访问者：灵巧的客人 - 为类增加新操作而不修改其内部结构。

## 数据库

### 云服务中不同数据库的便捷备忘单

<p> <img src="images/cloud-dbs2.png" /> </p>

为您的项目选择合适的数据库是一项复杂的任务。许多数据库选项，各自适用于不同的使用场景，可能会迅速导致决策疲劳。

我们希望这个备忘单能提供高层次的指导，以帮助您找到适合您项目需求的正确服务，避免潜在的陷阱。

注意：谷歌对其数据库使用案例的文档有限。虽然我们尽力查看可用的资料，并选择了最佳选项，但一些条目可能需要更准确。

### 支撑您的数据库的8种数据结构

答案会根据您的使用情况而有所不同。数据可以在内存或磁盘上进行索引。类似地，数据格式各异，例如数字、字符串、地理坐标等。系统可能是写重型或读重型。所有这些因素都会影响您选择的数据库索引格式。

<p> <img src="images/8-ds-db.jpg" /> </p>

以下是一些最常用的用于数据索引的数据结构：

- 跳表：一种常见的内存索引类型。在Redis中使用
- 哈希索引：一种非常常见的“映射”数据结构（或“集合”）的实现
- SSTable：不可变的磁盘“映射”实现
- LSM树：跳表 + SSTable。高写入吞吐量
- B树：基于磁盘的解决方案。稳定的读/写性能
- 倒排索引：用于文档索引。在Lucene中使用
- 后缀树：用于字符串模式搜索
- R树：多维搜索，例如寻找最近邻

### SQL语句在数据库中的执行过程是怎样的？

下面的图示展示了这个过程。请注意，不同数据库的架构不同，图示展示了一些常见的设计。

<p> <img src="images/sql execution order in db.jpeg" style="width: 580px" /> </p>

步骤1 - 通过传输层协议（如TCP）将SQL语句发送到数据库。

步骤2 - SQL语句被发送到命令解析器，在那里经过语法和语义分析，并生成查询树。

步骤3 - 查询树被发送到优化器。优化器生成执行计划。

步骤4 - 执行计划被发送到执行器。执行器从执行中提取数据。

步骤5 - 访问方法提供执行所需的数据提取逻辑，从存储引擎中检索数据。

步骤6 - 访问方法决定SQL语句是否为只读。如果查询是只读的（SELECT语句），则传递给缓冲管理器进行进一步处理。缓冲管理器在缓存或数据文件中查找数据。

步骤7 - 如果语句是UPDATE或INSERT，则传递给事务管理器进行进一步处理。

步骤8 - 在事务期间，数据处于锁定模式。这由锁管理器确保。它还确保事务的ACID属性。

### CAP 定理

CAP 定理是计算机科学中最著名的理论之一，但许多开发者可能对此有不同的理解。让我们来详细了解CAP定理及其令人困惑之处。

<p> <img src="images/cap theorem.jpeg" /> </p>

CAP 定理明确指出，一个分布式系统无法同时满足以下三种保证中的两种以上。

**一致性**：一致性意味着所有客户端在连接到任何节点（系统中的服务器或计算单元）时，看到的都是相同的数据。

**可用性**：可用性意味着任何请求数据的客户端都会收到响应，即使部分节点宕机。

**分区容忍性**：分区表示两个节点之间的通信中断。分区容忍性意味着尽管存在网络分区，系统仍然继续运行。

“三者择其二”的简化公式虽然有用，**但它可能会引发误导**。

1. 选择数据库并不容易。仅仅基于 CAP 定理来证明我们的选择是远远不够的。例如，公司并不是因为 Cassandra 是 AP 系统就选择它作为聊天应用程序的数据库。还有一些良好的特性使得 Cassandra 成为存储聊天消息的理想选择。我们需要更深入地探讨。

2. “CAP 仅限制设计空间中的一小部分：在存在分区的情况下实现完美可用性和一致性，而这种情况是罕见的。” 引自论文：CAP 十二年后：规则如何改变。

3. 该定理讨论的是 100% 的可用性和一致性。更现实的讨论将是在没有网络分区的情况下，延迟和一致性之间的权衡。有关更多详细信息，请参见 PACELC 定理。

**CAP 定理是否确实有用？**

我认为它仍然是有用的，因为它使我们对一系列权衡讨论保持开放的思维，但它只是故事的一部分。我们在选择合适的数据库时需要更深入的挖掘。

### 内存和存储类型

<p> <img src="images/Types_of_Memory_and_Storage.jpeg" style="width: 420px" /> </p>

### 可视化 SQL 查询

<p> <img src="images/sql-execution-order.jpg" style="width: 580px" /> </p>

SQL 语句由数据库系统通过多个步骤执行，包括：

- 解析 SQL 语句并检查其有效性  - 将 SQL 转换为内部表示，例如关系代数  - 优化内部表示并创建利用索引信息的执行计划  - 执行该计划并返回结果

SQL 的执行非常复杂，涉及许多考虑因素，例如：

- 索引和缓存的使用  - 表连接的顺序  - 并发控制  - 事务管理

### SQL 语言 

在 1986 年，SQL（结构化查询语言）成为标准。在接下来的 40 年中，它成为关系数据库管理系统的主导语言。阅读最新的标准（ANSI SQL 2016）可能会很耗时。我该如何学习它？

<p> <img src="images/how-to-learn-sql.jpg" /> </p>

SQL 语言有 5 个组成部分：

- DDL：数据定义语言，例如 CREATE、ALTER、DROP  - DQL：数据查询语言，例如 SELECT  - DML：数据操作语言，例如 INSERT、UPDATE、DELETE  - DCL：数据控制语言，例如 GRANT、REVOKE  - TCL：事务控制语言，例如 COMMIT、ROLLBACK

对于后端工程师来说，你可能需要了解其中的大部分内容。作为数据分析师，你可能需要对 DQL 有良好的理解。选择与您最相关的主题。

## 缓存

### 数据在各处被缓存

此图说明我们在典型架构中缓存数据的位置。

<p> <img src="images/where do we cache data.jpeg" style="width: 720px" /> </p>

在此过程中存在多个缓存层级。

在整个流程中存在**多个层次**。

1. 客户端应用：HTTP 响应可以被浏览器缓存。我们首次通过 HTTP 请求数据时，返回的数据在 HTTP 头中附带了过期策略；再次请求时，客户端应用会优先尝试从浏览器缓存中检索数据。
2. CDN：CDN 缓存静态 web 资源。客户端可以从附近的 CDN 节点检索数据。
3. 负载均衡器：负载均衡器也可以缓存资源。
4. 消息基础设施：消息代理会先将消息存储在磁盘上，然后消费者可以根据需要进行检索。根据保留策略，数据会在 Kafka 集群中缓存一段时间。
5. 服务：服务中存在多个层次的缓存。如果数据没有在 CPU 缓存中缓存，服务将尝试从内存中检索数据。有时服务会有二级缓存，将数据存储在磁盘上。
6. 分布式缓存：像 Redis 这样的分布式缓存将多个服务的键值对保存在内存中。它提供比数据库更好的读写性能。
7. 全文搜索：我们有时需要使用 ElasticSearch 等全文搜索引擎进行文档或日志的搜索。一份数据副本也会在搜索引擎中建立索引。
8. 数据库：即使在数据库中，我们也有不同级别的缓存：
   - WAL（预写日志）：数据会先写入 WAL，然后再构建 B 树索引。
   - 缓冲池：分配给缓存查询结果的内存区。
   - 物化视图：预先计算查询结果并将其存储在数据库表中，以提升查询性能。
   - 事务日志：记录所有事务和数据库更新。
   - 复制日志：用于记录数据库集群中的复制状态。

### 为什么 Redis 这么快？

有三个主要原因，如下图所示。

<p> <img src="images/why_redis_fast.jpeg" /> </p>

1. Redis 是基于 RAM 的数据存储。RAM 访问速度至少比随机磁盘访问快 1000 倍。
2. Redis 利用 IO 多路复用和单线程执行循环来提高执行效率。
3. Redis 利用几种高效的底层数据结构。

问题：另一个流行的内存存储是 Memcached。你知道 Redis 和 Memcached 之间的区别吗？

你可能已经注意到这张图的风格与我之前的帖子不同。请告诉我你更喜欢哪一种。

### Redis 可以如何使用？

<p> <img src="images/top-redis-use-cases.jpg" style="width: 520px" /> </p>

Redis 的用途不仅限于缓存。

正如图中所示，Redis 可以在多种场景中使用：

- 会话：我们可以使用 Redis 在不同服务之间共享用户会话数据。
- 缓存：我们可以使用 Redis 缓存对象或页面，尤其是热点数据。
- 分布式锁：我们可以使用 Redis 字符串在分布式服务之间获取锁。
- 计数器：我们可以计算文章的点赞数量或阅读量。
- 速率限制器：我们可以对某些用户 IP 应用速率限制器。
- 全局 ID 生成器：我们可以使用 Redis 的整数类型作为全局 ID。
- 购物车：我们可以使用 Redis Hash 在购物车中表示键值对。
- 计算用户留存：我们可以使用 Bitmap 表示用户每日登录并计算用户留存率。
- 消息队列：我们可以使用 List 作为消息队列。
- 排名：我们可以使用 ZSet 对文章进行排序。

### 顶级缓存策略

设计大规模系统通常需要仔细考虑缓存。
以下是五种经常被利用的缓存策略。

<p> <img src="images/top_caching_strategy.jpeg" style="width: 680px" /> </p>

## 微服务架构

### 一种典型的微服务架构是什么样的？

<p> <img src="images/typical-microservice-arch.jpg" style="width: 520px" /> </p>

下图显示了一种典型的微服务架构。

下面的图示展示了典型的微服务架构。

- 负载均衡器：负责在多个后端服务之间分配传入流量。
- CDN（内容分发网络）：CDN是一组地理分布的服务器，存储静态内容以加快交付。客户端首先在CDN中查找内容，如果未找到，则继续向后端服务请求。
- API网关：负责处理传入请求并将其路由到相关服务。它与身份提供者和服务发现进行通信。
- 身份提供者：负责用户的身份验证和授权。
- 服务注册与发现：微服务的注册和发现发生在此组件中，API网关通过此组件查找相关服务并进行通信。
- 管理：该组件负责监控服务。
- 微服务：微服务在不同领域中设计和部署。每个领域都有自己的数据库。API网关通过REST API或其他协议与微服务进行通信，而同一领域内的微服务则使用RPC（远程过程调用）相互通信。

微服务的好处：

- 可以快速设计、部署，并实现横向扩展。
- 每个领域可以由专门的团队独立维护。
- 每个领域的业务需求可以定制化，从而获得更好的支持。

### 微服务最佳实践

一图胜千言：开发微服务的9个最佳实践。

<p> <img src="images/microservice-best-practices.jpeg" /> </p>

当我们开发微服务时，需要遵循以下最佳实践：

1. 为每个微服务使用单独的数据存储
2. 保持代码在相似的成熟度水平
3. 每个微服务单独构建
4. 为每个微服务分配单一责任
5. 部署到容器中
6. 设计无状态服务
7. 采用领域驱动设计
8. 设计微前端
9. 协调整个微服务

### 微服务常用的技术栈是什么？

下面您会看到一个图示，展示了微服务的技术栈，分别是开发阶段和生产阶段。

<p> <img src="images/microservice-tech.jpeg" /> </p>

▶️ 𝐏𝐫𝐞-𝐏𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧

- 定义API - 这为前端和后端建立了合同。我们可以使用Postman或OpenAPI。
- 开发 - 前端开发通常使用Node.js或React，而后端开发则常用Java、Python或Go。此外，我们需要根据API定义更改API网关中的配置。
- 持续集成 - JUnit和Jenkins用于自动测试。代码打包成Docker镜像并作为微服务部署。

▶️ 𝐏𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧

- NGinx是负载均衡器的常见选择。Cloudflare提供CDN（内容分发网络）。
- API网关 - 我们可以使用Spring Boot作为网关，并使用Eureka/Zookeeper进行服务发现。
- 微服务部署在云上。我们可以选择AWS、微软Azure或Google GCP。
- 缓存与全文搜索 - Redis是缓存键值对的常见选择。Elasticsearch用于全文搜索。
- 通信 - 服务之间的通信可以使用消息基础设施Kafka或RPC。
- 持久化 - 我们可以使用MySQL或PostgreSQL作为关系数据库，Amazon S3作为对象存储。如果有必要，我们也可以使用Cassandra作为宽列存储。
- 管理与监控 - 为了管理众多微服务，常见的运维工具包括Prometheus、Elastic Stack和Kubernetes。

### 为什么Kafka快

有许多设计决策促成了Kafka的性能。本文将重点关注两个设计决策。我们认为这两个决策的影响最大。

<p> <img src="images/why_is_kafka_fast.jpeg" /> </p>

1. 第一个是Kafka依赖于顺序I/O。
2. 第二个设计选择，使Kafka具备性能优势的是其对效率的关注：zero copy原则。

该图示说明了数据在生产者和消费者之间的传输方式，以及zero copy的含义。

- 步骤1.1 - 1.3：生产者将数据写入磁盘 - 步骤2：消费者在没有zero copy的情况下读取数据

2.1 数据从磁盘加载到操作系统缓存

2.2 数据从操作系统缓存复制到Kafka应用程序

2.3 Kafka应用程序将数据复制到套接字缓冲区

2.4 数据从套接字缓冲区复制到网络卡

2.5 网络卡将数据发送给消费者

2.5 网络卡将数据发送给消费者

- 第3步：消费者以零拷贝方式读取数据

3.1：数据从磁盘加载到操作系统缓存中  
3.2 操作系统缓存通过 sendfile() 命令直接将数据复制到网络卡  
3.3 网络卡将数据发送给消费者  

零拷贝是一种优化方法，用于减少应用程序上下文和内核上下文之间多次数据复制。

## 支付系统

### 如何学习支付系统？

<p> <img src="images/learn-payments.jpg" /> </p>

### 为什么信用卡被称为“银行中盈利最丰厚的产品”？VISA/Mastercard是如何赚钱的？

下图显示了信用卡支付流程的经济学。

<p> <img src="images/how does visa makes money.jpg" style="width: 640px" /> </p>

1.&nbsp;&nbsp;持卡人支付商家100美元购买产品。

2.&nbsp;商家通过使用信用卡受益于更高的销售量，并需要补偿发卡银行和卡网络以提供支付服务。收单银行与商家设定了一个费率，称为“商户折扣费”。

3 - 4. 收单银行保留0.25美元作为收单行加价，1.75美元支付给发卡银行作为互换费。商户折扣费应覆盖互换费。

互换费由卡网络设定，因为每个发卡银行与每个商家的谈判效率较低。

5.&nbsp;&nbsp;卡网络与每个银行设定网络评估和费用，银行每月向卡网络支付其服务费用。例如，VISA对每次刷卡收取0.11%的评估费，加上每次使用费0.0195美元。

6.&nbsp;&nbsp;持卡人向发卡银行支付其服务费用。

为什么发卡银行应该得到补偿？

- 即使持卡人未能支付发卡银行，发卡银行仍然向商家付款。
- 发卡银行在持卡人向其付款之前就向商家付款。
- 发卡银行还有其他运营成本，包括管理客户账户、提供对账单、欺诈检测、风险管理、清算与结算等。

### 当我们在商家的店里刷信用卡时，VISA是如何工作的？

<p> <img src="images/visa_payment.jpeg" /> </p>

VISA、Mastercard和美国运通作为清算和结算资金的卡网络。收单银行和发卡银行可以是——并且通常是——不同的。如果银行之间逐一结算交易而没有中介，每个银行将不得不与其他所有银行结算交易。这是相当低效的。

下图显示了VISA在信用卡支付过程中的角色。涉及两个流程。授权流程发生在客户刷信用卡时。捕获和结算流程发生在商家希望在一天结束时收钱时。

- 授权流程

步骤0：发卡银行向其客户发放信用卡。

步骤1：持卡人想购买产品并在商家的销售点（POS）终端刷信用卡。

步骤2：POS终端将交易信息发送给提供POS终端的收单银行。

步骤3和4：收单银行将交易信息发送到卡网络，也称为卡计划。卡网络将交易信息发送到发卡银行进行批准。

步骤4.1、4.2和4.3：如果交易获得批准，发卡银行将冻结资金。批准或拒绝信息将发送回收单银行以及POS终端。

- 捕获和结算流程

步骤1和2：商家希望在一天结束时收取款项，因此他们在POS终端上点击“结算”。交易以批量方式发送给收单银行。收单银行将含有交易的批量文件发送给卡网络。

步骤3：卡网络对来自不同收单银行的交易进行清算，并将清算文件发送给不同的发卡银行。

步骤4：发卡银行核实清算文件的正确性，并将钱转给相关的收单银行。

步骤5：收单银行随后将钱转给商家的银行。

步骤4：卡网络对来自不同收单银行的交易进行清算。清算是一个相互抵消交易的过程，从而减少总交易数量。

在此过程中，卡网络承担与每个银行沟通的职责，并作为回报收取服务费。

### 全球支付系统系列（第一部分）：印度统一支付接口（UPI）

什么是UPI？UPI是由印度国家支付公司开发的即时实时支付系统。

它今天占印度数字零售交易的60%。

UPI = 支付标记语言 + 可互操作支付的标准


<p> <img src="images/how-does-upi-work.png"  style="width: 600px" /> </p>


## DevOps

### DevOps与SRE与平台工程。有什么区别？

DevOps、SRE和平台工程的概念是在不同的时间出现的，由不同的个人和组织发展而来。

<p> <img src="images/devops-sre-platform.jpg" /> </p>

DevOps作为一个概念由Patrick Debois和Andrew Shafer在2009年的敏捷会议上提出。他们旨在通过促进协作文化和对整个软件开发生命周期的共同责任来弥合软件开发与运营之间的差距。

SRE，即站点可靠性工程，最早由谷歌在2000年代初提出，以应对管理大规模复杂系统的运营挑战。谷歌开发了SRE实践和工具，例如Borg集群管理系统和Monarch监控系统，以提高其服务的可靠性和效率。

平台工程是一个更新的概念，建立在SRE工程的基础上。平台工程的确切起源不太明确，但普遍理解为是对DevOps和SRE实践的扩展，专注于提供一个支持整个业务视角的产品开发综合平台。

值得注意的是，尽管这些概念在不同时间出现，但它们都与改善软件开发和运营中的协作、自动化和效率的更广泛趋势相关。

### 什么是k8s（Kubernetes）？

K8s是一个容器编排系统。它用于容器的部署和管理。它的设计受到谷歌内部系统Borg的重大影响。

<p> <img src="images/k8s.jpeg" style="width: 680px" /> </p>

一个k8s集群由一组工作机器（称为节点）组成，这些机器运行容器化应用。每个集群至少有一个工作节点。

工作节点托管Pod，这些Pod是应用工作负载的组成部分。控制平面管理集群中的工作节点和Pods。在生产环境中，控制平面通常跨多个计算机运行，且一个集群通常运行多个节点，以提供容错能力和高可用性。

- 控制平面组件

1. API Server

    API服务器与k8s集群中的所有组件进行通信。所有对Pods的操作都是通过与API服务器交谈来执行的。

2. 调度器

    调度器观察Pod的工作负载，并在新创建的Pods上分配负载。

3. 控制器管理器

    控制器管理器运行控制器，包括节点控制器、任务控制器、端点切片控制器和服务账号控制器。

4. Etcd

    etcd是一个键值存储，用作Kubernetes所有集群数据的后备存储。

- 节点

1. Pods

    Pod是一组容器，是k8s管理的最小单位。每个Pod中每个容器都有一个相同的IP地址。

2. Kubelet

    在集群中的每个节点上运行的代理。它确保Pods中的容器正在运行。

3. Kube Proxy

    Kube-proxy是一种网络代理，运行在集群中每个节点上。它路由从服务进入节点的流量。它将工作请求转发给正确的容器。

### Docker与Kubernetes。我们应该使用哪个？

<p> <img src="images/docker-vs-k8s.jpg" style="width: 680px" /> </p>

什么是Docker?

Docker是一个开源平台，允许你在隔离的容器中打包、分发和运行应用程序。它专注于容器化，提供轻量级环境，封装应用程序及其依赖项。

什么是Kubernetes?

Kubernetes，通常称为K8s，是一个开源容器编排平台。它提供了一个框架，用于自动化容器化应用程序在多个节点集群中的部署、扩展和管理。

它们之间有什么不同？

Docker：Docker在单个操作系统主机的容器层面操作。

你必须手动管理每个主机，为多个相关容器设置网络、安全策略和存储可能相当复杂。

Kubernetes：Kubernetes在集群层面运行，管理多个主机上的多个容器化应用程序，提供负载均衡、扩展及确保应用程序所需状态等任务的自动化。

简而言之，Docker专注于容器化及在单个主机上运行容器，而Kubernetes专门管理和编排在多个主机上大规模运行的容器。

### Docker是如何工作的？

下图展示了Docker的架构，以及当我们运行“docker build”、“docker pull”和“docker run”时的工作原理。

<p> <img src="images/docker.jpg" style="width: 680px" /> </p>

Docker架构包含三个组件：

- Docker客户端

    Docker客户端与Docker守护进程进行通信。

- Docker主机

    Docker守护进程监听Docker API请求，并管理Docker对象，如镜像、容器、网络和卷。

- Docker注册表

    Docker注册表用于存储Docker镜像。Docker Hub是一个任何人均可使用的公共注册表。

我们以“docker run”命令为例。

  1. Docker从注册表中拉取镜像。
  2. Docker创建一个新容器。
  3. Docker为容器分配一个读写文件系统。
  4. Docker创建一个网络接口，将容器连接到默认网络。
  5. Docker启动容器。

## GIT

### Git命令是如何工作的

首先，必须明确我们的代码存储在哪里。常见的假设是只有两个位置——一个在远程服务器上，如GitHub，另一个在本地机器上。然而并不完全准确。Git在我们的机器上维护三种本地存储，这意味着我们的代码实际上可以在四个地方找到：

<p> <img src="images/git-commands.png" style="width: 600px" /> </p>

- 工作目录：我们编辑文件的地方
- 暂存区：临时存放文件以待下一个提交的地方
- 本地库：包含已提交的代码
- 远程库：存储代码的远程服务器

大多数Git命令主要在这四个位置之间移动文件。

### Git是如何工作的？

下图展示了Git的工作流程。

<p> <img src="images/git-workflow.jpeg" style="width: 520px" /> </p>

Git是一个分布式版本控制系统。

每个开发者维护主库的本地副本，并在本地副本上进行编辑和提交。

提交非常快速，因为该操作不会与远程库交互。

如果远程库崩溃，文件可以从本地库中恢复。

### Git merge vs. Git rebase

有什么区别？

<p> <img src="images/git-merge-git-rebase.jpeg" style="width: 680px" /> </p>

当我们将**更改合并**从一个Git分支到另一个时，可以使用‘git merge’或‘git rebase’。下图展示了这两个命令的工作原理。

**Git merge**

在主分支中创建一个新提交G'。G'将主分支和特性分支的历史关联起来。

Git merge是**非破坏性的**，主分支和特性分支均不发生变化。

**Git rebase**

Git rebase将特性分支的历史移动到主分支的头部。它为特性分支中的每个提交创建新的提交E'、F'和G'。

rebase的好处在于它生成线性的**提交历史**。

如果不遵循“Git rebase的黄金法则”，rebase可能会很危险。

**Git rebase的黄金法则**

**Git Rebase 的黄金法则**

永远不要在公共分支上使用它！

## 云服务

### 不同云服务的实用备忘单（2023 版）

<p> <img src="images/cloud-compare.jpg" /> </p>

### 什么是云原生？

下面是自1980年代以来架构和流程演变的图示。 

<p> <img src="images/cloud-native.jpeg" style="width: 640px" /> </p>

组织可以使用云原生技术在公共、私有和混合云上构建和运行可扩展的应用程序。 

这意味着应用程序被设计为利用云特性，因此它们对负载具有弹性且易于扩展。 

云原生包括4个方面： 

1. 开发过程 

    这个过程已经从瀑布模型发展到敏捷再到DevOps。 

2. 应用架构 

    架构已经从单体架构变为微服务。每个服务都设计得很小，可以适应云容器中的有限资源。 

3. 部署与打包 

    应用程序曾经是在物理服务器上部署的。大约在2000年，通常在虚拟服务器上部署那些对延迟不敏感的应用程序。使用云原生应用程序时，它们被打包成docker镜像并在容器中部署。 

4. 应用基础设施 

    应用程序在云基础设施上大规模部署，而不是自托管服务器上。 

## 开发者生产力工具

### 可视化 JSON 文件

嵌套的 JSON 文件难以阅读。

**JsonCrack** 从 JSON 文件生成图表，使其易于阅读。

此外，生成的图表可以下载为图片。

<p> <img src="images/json-cracker.jpeg" /> </p>

### 自动将代码转换为架构图

<p> <img src="images/diagrams_as_code.jpeg" style="width: 640px" /> </p>

它的功能是什么？

- 用 Python 代码绘制云系统架构。
- 图表也可以直接在 Jupyter Notebooks 中渲染。
- 不需要设计工具。
- 支持以下供应商：AWS、Azure、GCP、Kubernetes、阿里云、Oracle Cloud 等。

[Github 仓库](https://github.com/mingrammer/diagrams)

## Linux

### 解释 Linux 文件系统

<p> <img src="images/linux-file-systems.jpg" style="width: 680px" /> </p>

Linux 文件系统曾经像一个无序的城镇，个人可以随意建造自己的房屋。然而，在1994年，文件系统层次标准（FHS）被引入，以给 Linux 文件系统带来秩序。

通过实施诸如 FHS 这样的标准，软件可以确保在各种 Linux 发行版之间具有一致的布局。然而，并非所有的 Linux 发行版都严格遵循这个标准。它们常常结合自己的独特元素或满足特定需求。
要熟练掌握这个标准，您可以从探索开始。使用 "cd" 命令进行导航，使用 "ls" 命令列出目录内容。想象一下文件系统就像一棵树，从根目录 (/) 开始。随着时间的推移，这将变成您的第二天性，使您成为一名熟练的 Linux 管理员。

### 你应该知道的 18 个最常用的 Linux 命令 

Linux 命令是与操作系统交互的指令。它们帮助管理文件、目录、系统进程及系统的许多其他方面。您需要熟悉这些命令，以有效和高效地导航和维护基于 Linux 的系统。 

下面的图表显示了流行的 Linux 命令：

<p> <img src="images/18 Most-Used Linux Commands You Should Know-01.jpeg" style="width: 680px" /> </p>

- ls - 列出文件和目录
- cd - 更改当前目录
- mkdir - 创建新目录
- rm - 删除文件或目录
- cp - 复制文件或目录
- mv - 移动或重命名文件或目录
- chmod - 更改文件或目录权限
- grep - 在文件中搜索模式
- find - 搜索文件和目录
- tar - 操作 tarball 归档文件
- vi - 使用文本编辑器编辑文件
- cat - 显示文件内容
- top - 显示进程和资源使用情况
- ps - 显示进程信息
- kill - 通过发送信号终止进程
- du - 估计文件空间使用情况
- ifconfig - 配置网络接口
- ping - 测试主机之间的网络连通性

## 安全

### HTTPS 如何工作？

安全超文本传输协议（HTTPS）是超文本传输协议（HTTP）的扩展。HTTPS 使用传输层安全性（TLS）加密数据进行传输。如果数据在网上被劫持，劫持者得到的只是二进制代码。

<p> <img src="images/https.jpg" /> </p>

数据是如何加密和解密的？

步骤1 - 客户端（浏览器）和服务器建立TCP连接。

步骤2 - 客户端向服务器发送“客户端问候”。该消息包含一组所需的加密算法（密码套件）和它可以支持的最新TLS版本。服务器回复“服务器问候”，以便浏览器知道它是否能够支持这些算法和TLS版本。

然后，服务器将SSL证书发送给客户端。该证书包含公钥、主机名、到期日期等。客户端对证书进行验证。

步骤3 - 在验证SSL证书后，客户端生成一个会话密钥，并使用公钥对其进行加密。服务器接收加密的会话密钥，并使用私钥进行解密。

步骤4 - 现在客户端和服务器都持有相同的会话密钥（对称加密），加密的数据在安全的双向通道中传输。

为什么HTTPS在数据传输过程中切换到对称加密？主要有两个原因：

1. 安全性：非对称加密只能单向进行。这意味着如果服务器尝试将加密数据发送回客户端，任何人都可以使用公钥解密数据。

2. 服务器资源：非对称加密增加了相当多的数学开销，不适合于长会话中的数据传输。

### 用简单的术语解释OAuth 2.0

OAuth 2.0是一个强大而安全的框架，允许不同应用程序在不共享敏感凭据的情况下安全地代表用户相互交互。

<p> <img src="images/oAuth2.jpg" /> </p>

在OAuth中，涉及的实体包括用户、服务器和身份提供者（IDP）。

OAuth令牌能做什么？

当您使用OAuth时，您将获得一个代表您的身份和权限的OAuth令牌。该令牌可以做几件重要的事情：

单点登录（SSO）：使用OAuth令牌，您可以通过一次登录访问多个服务或应用，让生活更轻松、更安全。

跨系统授权：OAuth令牌允许您在各种系统之间共享您的授权或访问权限，因此您不必在每个地方单独登录。

访问用户个人资料：具有OAuth令牌的应用程序可以访问您允许的用户个人资料的某些部分，但不会看到所有内容。

请记住，OAuth 2.0旨在保护您和您的数据安全，同时使您在不同应用程序和服务之间的在线体验无缝且方便。

### 四种最常用的身份验证机制

<p> <img src="images/top4-most-used-auth.jpg" /> </p>

1. SSH密钥：

   使用加密密钥安全访问远程系统和服务器

2. OAuth令牌：

   为第三方应用程序提供对用户数据的有限访问的令牌

3. SSL证书：

   数字证书确保服务器和客户端之间的安全和加密通信

4. 凭据：

   用户身份验证信息用于验证并授予对各种系统和服务的访问权限

### 会话、cookie、JWT、令牌、SSO和OAuth 2.0 - 他们是什么？

这些术语都涉及用户身份管理。当您登录一个网站时，您声明您的身份（识别）。您的身份得到验证（认证），并授予所需的权限（授权）。过去提出了许多解决方案，列表仍在持续增长。

<p> <img src="images/session.jpeg" /> </p>

从简单到复杂，这是我对用户身份管理的理解：

- WWW-Authenticate是最基本的方法。浏览器会要求您输入用户名和密码。由于无法控制登录生命周期，这种方法今天很少使用。

- 更细致地控制登录生命周期的是会话cookie。服务器维护会话存储，浏览器保持会话ID。cookie通常仅适用于浏览器，不适合移动应用。

- 为了解决兼容性问题，可以使用令牌。客户端将令牌发送给服务器，服务器验证该令牌。缺点是令牌需要加密和解密，这可能是耗时的。

- JWT是一种表示令牌的标准方式。该信息可以被验证和信任，因为它是数字签名的。由于JWT包含签名，因此不需要在服务器端保存会话信息。

- 通过使用SSO（单点登录）技术，您只需登录一次就能访问多个网站。这种方式采用CAS（中央认证服务）来管理跨站点的身份信息。

- 通过使用OAuth 2.0协议，您可以授权一个网站访问您存储在另一个网站上的信息，而无需共享您的登录凭据。

### 如何在数据库中安全存储密码以及如何验证密码？

<p> <img src="images/salt.jpg" style="width: 720px" /> </p>

**密码存储的注意事项**

- 以明文存储密码并不是一个好主意，因为任何具有内部访问权限的人都可以看到它们。

- 直接存储密码哈希远远不够，因为它容易受到预计算攻击（如彩虹表攻击）。

- 为了减少预计算攻击，我们对密码进行加盐处理。

**什么是盐？**

根据OWASP（开放网络应用安全项目）指南，“盐值是一个唯一的、随机生成的字符串，在哈希处理过程中被添加到每个密码中”。

**如何存储密码和盐？**

1. 通过加盐，每个密码的哈希结果都是唯一的。
2. 可以使用以下格式将密码存储在数据库中：hash(password + salt)。

**如何验证密码？**

验证密码可以经过以下过程：

1. 客户端输入密码。
2. 系统从数据库中获取相应的盐。
3. 系统将盐附加到密码上并进行hash处理。我们称hash值为H1。
4. 系统将H1与存储在数据库中的hash值H2进行比较。如果它们相同，则密码有效。

### 向10岁小孩解释JSON Web Token（JWT）

<p> <img src="images/jwt.jpg" /> </p>

想象你有一个特殊的盒子，叫做JWT。在这个盒子里，有三个部分：header、payload和signature。

header就像盒子外面的标签。它告诉我们这是什么类型的盒子以及它是如何被保护的。它通常是以一种叫做JSON的格式书写的，这只是用花括号{ }和冒号:来组织信息的一种方式。

payload就像你想发送的实际消息或信息。可能是你的名字、年龄或你想分享的任何其他数据。它也是以JSON格式书写的，所以易于理解和处理。

现在，signature就是让JWT安全的关键。它就像一个特殊的印记，只有发送者知道如何创建。signature是使用秘密代码生成的，有点像密码。这个signature确保没有人可以在发送者不知道的情况下篡改JWT的内容。

当你想将JWT发送到服务器时，你将header、payload和signature放入盒子里。然后你将它发送到服务器。服务器可以轻松读取header和payload，以了解你是谁以及你想做什么。

### Google Authenticator（或其他类型的双因素身份验证器）是如何工作的？

Google Authenticator常用于在启用双因素身份验证时登录我们的账户。它如何保证安全？

Google Authenticator是一种基于软件的身份验证器，实施了两步验证服务。下面的图表提供了详细信息。

<p> <img src="images/google_authenticate.jpeg" /> </p>

涉及两个阶段：

- 阶段1 - 用户启用Google两步验证。
- 阶段2 - 用户使用身份验证器进行登录等。

让我们看一下这些阶段。

**阶段1**

步骤1和2：鲍勃打开网页以启用两步验证。前端请求一个秘密密钥。身份验证服务为鲍勃生成秘密密钥并将其存储在数据库中。

步骤3：身份验证服务将URI返回给前端。URI由key issuer、username和secret key组成。URI以二维码的形式显示在网页上。

步骤4：鲍勃随后使用Google Authenticator扫描生成的二维码。秘密密钥存储在身份验证器中。

**第二阶段**

步骤 1 和 2：博比想用 Google 两步身份验证登录一个网站。为此，他需要密码。每 30 秒，Google Authenticator 使用 TOTP（基于时间的一次性密码）算法生成一个 6 位数字的密码。博比使用这个密码登录网站。

步骤 3 和 4：前端将博比输入的密码发送到后端进行身份验证。身份验证服务从数据库中读取密钥，并使用与前端相同的 TOTP 算法生成一个 6 位数字的密码。

步骤 5：身份验证服务将客户端和服务器生成的两个密码进行比较，并将比较结果返回给前端。博比只有在两个密码匹配的情况下才能继续登录。

这种身份验证机制安全吗？

- 密钥会被别人盗取吗？

    我们需要确保密钥是通过 HTTPS 传输的。身份验证器应用和数据库存储密钥，我们需要确保密钥被加密。

- 6 位数字的密码会被黑客猜到吗？

    不会。密码有 6 位，因此生成的密码有 100 万种可能的组合。此外，密码每 30 秒会变动一次。如果黑客想在 30 秒内猜出密码，他们需要每秒尝试 30,000 种组合。

## 真实案例研究

### Netflix 的技术栈

这篇文章基于许多 Netflix 工程博客和开源项目的研究。如果您发现任何不准确的地方，请随时告知我们。

<p> <img src="images/netflix tech stack.png" style="width: 680px" /> </p>

**移动和网页**：Netflix 采用 Swift 和 Kotlin 开发移动应用。对于其网页应用，它使用 React。

**前端/服务器通信**：Netflix 使用 GraphQL。

**后端服务**：Netflix 依赖 ZUUL、Eureka、Spring Boot 框架等技术。

**数据库**：Netflix 使用 EV cache、Cassandra、CockroachDB 及其他数据库。

**消息/流媒体**：Netflix 采用 Apache Kafka 和 Fink 进行消息和流媒体处理。

**视频存储**：Netflix 使用 S3 和 Open Connect 进行视频存储。

**数据处理**：Netflix 利用 Flink 和 Spark 进行数据处理，随后使用 Tableau 进行可视化。Redshift 用于处理结构化数据仓库信息。

**CI/CD**：Netflix 使用各种工具，如 JIRA、Confluence、PagerDuty、Jenkins、Gradle、Chaos Monkey、Spinnaker、Atlas 等，来进行 CI/CD 过程。

### Twitter 架构 2022

是的，这就是实际的 Twitter 架构。它由埃隆·马斯克发布，我们进行了更好的可读性重绘。

<p> <img src="images/twitter-arch.jpeg" /> </p>

### Airbnb 微服务架构在过去 15 年中的演变

Airbnb 的微服务架构经历了 3 个主要阶段。

<p> <img src="images/airbnb_arch.jpeg" /> </p>

单体架构（2008 - 2017）

Airbnb 最初是一个简单的东道主和客人市场。这是构建在 Ruby on Rails 应用中的单体架构。

挑战是什么？

- 团队责任混淆 + 无主代码 - 部署缓慢

微服务（2017 - 2020）

微服务旨在解决这些挑战。微服务架构的关键服务包括：

- 数据获取服务 - 业务逻辑数据服务 - 写入工作流服务 - UI 聚合服务 - 每个服务由一个负责团队拥有

挑战是什么？

数百个服务和依赖关系使人类管理变得困难。

微 + 宏服务（2020 - 至今）

这是 Airbnb 当前正在研究的内容。微服务和宏服务的混合模型专注于 API 的统一。

### Monorepo 与 Microrepo

哪个更好？为什么不同的公司选择不同的选项？

<p> <img src="images/monorepo-microrepo.jpg" /> </p>

Monorepo 并不新颖；Linux 和 Windows 都是使用 Monorepo 创建的。为了提高可扩展性和构建速度，Google 开发了内部专用工具链，以更快进行扩展，并制定严格的编码质量标准以保持一致性。

亚马逊和 Netflix 是微服务理念的主要倡导者。这种方法自然将服务代码分离到不同的代码库中。它扩展较快，但可能在后期出现治理痛点。

在 Monorepo 中，每个服务是一个文件夹，每个文件夹都有一个 BUILD 配置和 OWNERS 权限控制。每个服务成员对自己的文件夹负责。

相反地，在Microrepo中，每个服务负责其自己的存储库，构建配置和权限通常是针对整个存储库设置的。

在Monorepo中，依赖关系跨整个代码库共享，不考虑您的业务，因此当版本升级时，每个代码库都会升级其版本。

在Microrepo中，依赖关系在每个存储库中进行控制。企业可以根据自己的计划选择升级版本的时间。

Monorepo有一个标准的提交规范。谷歌的代码审查流程因设定高标准而闻名，确保了Monorepo的质量标准一致性，不论业务领域如何。

Microrepo可以设定自己的标准，或者通过采纳最佳实践来采用共享标准。它能够更快速地扩展以适应企业需求，但代码质量可能会有所不同。  
Google工程师开发了Bazel，Meta开发了Buck。此外，还有其他开源工具可供使用，如Nx、Lerna等。

多年来，Microrepo支持的工具更多，包括Java的Maven和Gradle、NodeJS的NPM、C/C++的CMake等。

### 你会如何设计Stack Overflow网站？

如果你的答案是on-premise服务器和单体（在下面的图片中），你可能会在面试中失败，但现实就是如此！

<p> <img src="images/stackoverflow.jpg" /> </p>

**人们认为它应该是这样的**

面试官可能期待的是图片上半部分的样子。

- 微服务用于将系统分解为小组件。
- 每个服务都有自己的数据库。大量使用缓存。
- 服务是分片的。
- 服务通过消息队列异步地彼此通信。
- 服务使用事件源和CQRS来实现。
- 展示在分布式系统（如最终一致性、CAP定理等）方面的知识。

**实际上是这样的**

Stack Overflow仅用9台on-premise Web服务器就处理了所有流量，而且它是单体！它使用自己的服务器，并且不依赖云端。

这与我们这些天的所有流行观念相悖。

### 为什么亚马逊Prime视频监控从无服务器转向单体？如何节省90%的成本？

下面的图表显示了迁移前后的架构比较。

<p> <img src="images/serverless-to-monolithic.jpeg" /> </p>

什么是亚马逊Prime视频监控服务？

Prime视频服务需要监控数千个实时流的质量。监控工具会实时自动分析流并识别质量问题，如块损坏、视频冻结和同步问题。这是客户满意度的重要过程。

有3个步骤：媒体转换器、缺陷检测器和实时通知。

- 旧架构有什么问题？

  旧架构基于亚马逊Lambda，这对于快速构建服务来说很好。然而，当以大规模运行该架构时，它并不经济。两项最昂贵的操作是：

1. 编排工作流——AWS步骤函数按状态转换向用户收费，而编排每秒执行多个状态转换。

2. 分布式组件之间的数据传递——中间数据存储在亚马逊S3中，以便下一阶段下载。当量很大时，下载可能会很昂贵。

- 单体架构节省90%成本

  单体架构旨在解决成本问题。仍然有3个组件，但媒体转换器和缺陷检测器部署在同一进程中，节省了数据传输的成本。令人惊讶的是，这种部署架构的变化导致了90%的成本节省！

这是一个有趣而独特的案例研究，因为微服务已成为技术行业的首选和流行选择。看到我们更多地讨论架构的演变以及对其利弊进行更诚实的讨论是件好事。将组件分解为分布式微服务是有成本的。

- 亚马逊领导对此有什么看法？

  亚马逊首席技术官Werner Vogels：“构建**evolvable 软件系统**是一种战略，而不是一种宗教。以开放的心态重新审视你的架构是必须的。”

  前亚马逊副总裁可持续性Adrian Cockcroft：“Prime视频团队遵循了一条我称之为**无服务器优先**的路径……我并不提倡**仅无服务器**。”

### Disney Hotstar如何在比赛期间捕捉到50亿个表情符号？

<p> <img src="images/hotstar_emojis.jpeg" style="width: 720px" /> </p>

1. 客户通过标准HTTP请求发送表情符号。您可以将Golang服务视为典型的Web服务器。选择Golang是因为它具备出色的并发支持能力。Golang中的线程是轻量级的。

2. 由于写入量非常高，因此使用Kafka（消息队列）作为缓冲区。

3. 表情符号数据由一个称为Spark的流处理服务进行聚合。它每2秒聚合一次数据，此配置可调整。时间间隔的选择需要权衡。较短的间隔意味着表情符号更快地传递给其他客户，但这也意味着需要更多的计算资源。

4. 聚合的数据写入另一个Kafka。

5. PubSub消费者从Kafka中提取聚合的表情符号数据。

6. 表情符号通过PubSub基础设施实时传递给其他客户。PubSub基础设施非常重要。Hotstar考虑了以下协议：Socketio、NATS、MQTT和gRPC，最终选择了MQTT。

LinkedIn采用了类似的设计，每秒传输一百万个点赞。

### Discord如何存储万亿条信息

下面的图表展示了Discord消息存储的演变：

<p> <img src="images/discord-store-messages.jpg" /> </p>

MongoDB ➡️ Cassandra ➡️ ScyllaDB

2015年，Discord的第一个版本建立在单个MongoDB副本之上。大约在2015年11月，MongoDB存储了一亿条消息，RAM再也无法容纳数据和索引。延迟变得不可预测。消息存储被迁移到另一个数据库。于是选择了Cassandra。

2017年，Discord有12个Cassandra节点，存储了数十亿条消息。

到2022年初，它有177个节点，存储了万亿条消息。在这一点上，延迟变得不可预测，维护操作变得过于昂贵。

这些问题的原因有几个：

- Cassandra使用LSM树作为内部数据结构。读取的开销高于写入。在一个拥有数百用户的服务器上可能会有许多并发读取，导致热点。
- 维护集群，例如压缩SSTables，会影响性能。
- 垃圾回收暂停会导致显著的延迟峰值。

ScyllaDB是兼容Cassandra的数据库，用C++编写。Discord重新设计了其架构，以实现单体API、用Rust编写的数据服务和基于ScyllaDB的存储。

ScyllaDB中的p99读取延迟为15毫秒，而Cassandra中为40-125毫秒。p99写入延迟为5毫秒，而Cassandra中为5-70毫秒。

### YouTube、TikTok直播或Twitch上的视频直播是如何工作的？

直播与常规流媒体不同，因为视频内容通过互联网实时发送，通常延迟仅为几秒钟。

下面的图表解释了在后台发生了什么，使这一切成为可能。

<p> <img src="images/live_streaming_updated.jpg" style="width: 640px" /> </p>

步骤1：原始视频数据通过麦克风和摄像机捕获。数据被发送到服务器端。

步骤2：视频数据被压缩和编码。例如，压缩算法将背景和其他视频元素分开。压缩后，视频被编码为H.264等标准。经过此步骤后，视频数据的大小要小得多。

步骤3：编码后数据被划分为较小的段，通常长度为几秒，这样下载或流式传输所需时间大大减少。

步骤4：分段数据被发送到流媒体服务器。流媒体服务器需要支持不同的设备和网络条件。这称为“自适应比特率流”。这意味着在步骤2和3中我们需要生成不同比特率的多个文件。

步骤5：直播数据被推送到由CDN（内容分发网络）支持的边缘服务器。数百万观众可以从附近的边缘服务器观看视频。CDN显著降低了数据传输延迟。

步骤6：观众的设备解码和解压缩视频数据，并在视频播放器中播放视频。

步骤7和8：如果视频需要存储以供回放，编码后的数据将被发送到存储服务器，观众可以稍后向其请求回放。

直播的标准协议包括：

- RTMP（实时消息传输协议）：最初由Macromedia开发，用于在Flash播放器和服务器之间传输数据。目前主要用于互联网视频流媒体传输。请注意，像Skype这样的在线视频会议应用程序使用RTC（实时通信）协议以降低延迟。

- HLS（HTTP直播流）：它需要H.264或H.265编码。苹果设备仅支持HLS格式。

- DASH（基于HTTP的动态自适应流）：DASH不支持苹果设备。

- HLS和DASH都支持自适应码率流。

## 许可证

<p xmlns:cc="http://creativecommons.org/ns#" >本作品采用 <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-ND 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1"></a></p>