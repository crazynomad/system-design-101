## 通信协议

  
架构风格定义了应用程序编程接口（API）的不同组件如何相互交互。因此，它们通过提供标准的设计和构建 API 的方法，确保效率、可靠性和与其他系统集成的便利性。以下是最常用的风格：

![](../images/api-architecture-styles.png)

*    SOAP：
    
      
    成熟、全面、基于 XML 的
    
      
    最适合企业应用
    
*    RESTful：
    
      
    流行、易于实施的 HTTP 方法
    
     适用于网络服务
    
*    GraphQL：
    
      
    查询语言，请求特定数据
    
      
    减少网络开销，更快的响应
    
*    gRPC：
    
      
    现代、高性能、协议缓冲器
    
      
    适用于微服务架构
    
*    WebSocket：
    
      
    实时、双向、持久连接
    
      
    低延迟数据交换的理想选择
    
*    Webhook：
    
      
    事件驱动，HTTP 回调，异步
    
      
    当事件发生时通知系统
    

###  REST API 与 GraphQL

  
在 API 设计方面，REST 和 GraphQL 各有其优点和缺点。

  
下面的图表显示了 REST 和 GraphQL 之间的快速比较。

![](../images/graphQL.jpg)

 REST RESTful Web 服务是一种基于 REST 架构风格设计的 Web 服务。REST 代表“表述性状态转移”，是一种设计风格，用于构建分布式系统

*     
    使用标准的 HTTP 方法，如 GET、POST、PUT、DELETE 来进行 CRUD 操作。
*     
    在需要简单、统一的接口连接不同服务/应用程序时表现良好。
*     
    缓存策略很容易实现。
*     
    缺点是可能需要多次往返来从不同的端点收集相关数据。

GraphQL

*     
    为客户提供一个单一的端点，以精确获取他们所需的数据。
*     
    客户在嵌套查询中指定所需的确切字段，服务器返回优化的有效负载，仅包含这些字段。
*     
    支持变异以修改数据和订阅以实时通知。
*     
    非常适合从多个来源聚合数据，并且与快速发展的前端需求配合良好。
*     
    然而，它将复杂性转移到客户端，并且如果没有得到适当保护，可能会允许滥用查询
*     
    缓存策略可能比 REST 更复杂。

  
REST 和 GraphQL 之间的最佳选择取决于应用程序和开发团队的具体要求。GraphQL 非常适合复杂或经常变化的前端需求，而 REST 适用于偏好简单和一致契约的应用程序。

  
API 方法都不是万能解决方案。仔细评估需求和权衡是选择正确风格的重要因素。REST 和 GraphQL 都是公认的用于暴露数据和支持现代应用程序的选项。

###  gRPC 是如何工作的？

  
RPC（远程过程调用）之所以被称为“**远程**”，是因为在微服务架构下，当服务部署在不同服务器上时，它可以实现远程服务之间的通信。从用户的角度来看，它就像是一个本地函数调用。

  
下面的图表说明了的整体数据流程。

![](../images/grpc.jpg)

  
步骤 1：客户端发起一个 REST 调用。请求体通常是 JSON 格式。

  
步骤 2 - 4：订单服务（gRPC 客户端）接收 REST 调用，对其进行转换，并向支付服务发起 RPC 调用。gRPC 将**客户端存根**编码为二进制格式并将其发送到低级传输层。

  
第 5 步：gRPC 通过 HTTP2 将数据包发送到网络。由于二进制编码和网络优化，据说 gRPC 比 JSON 快 5 倍。

  
步骤 6 - 8：支付服务（gRPC 服务器）接收来自网络的数据包，解码它们，并调用服务器应用程序。

  
步骤 9 - 11：结果从服务器应用程序返回，被编码并发送到传输层。

  
步骤 12 - 14：订单服务接收数据包，解码数据，并将结果发送给客户端应用程序。

###  什么是 Webhook？

  
下面的图表显示了轮询和 Webhook 之间的比较。

![](../images/webhook.jpeg)

  
假设我们经营一家电子商务网站。客户通过 API 网关将订单发送到订单服务，订单服务将订单发送到支付服务进行支付交易。支付服务然后与外部支付服务提供商（PSP）进行通信，以完成交易。

  
处理与外部 PSP 的通信有两种方式。

 **1. 短轮询** 

  
将付款请求发送给 PSP 后，支付服务不断向 PSP 询问付款状态。经过几轮后，PSP 最终返回了状态。

  
短轮询有两个缺点：

*     
    状态的持续轮询需要支付服务的资源。
*     
    外部服务直接与支付服务通信，造成安全漏洞。

 **2. Webhook Webhook** 

  
我们可以向外部服务注册一个 Webhook。这意味着：当您有关于请求的更新时，请在特定的 URL 上回调我。当 PSP 完成处理后，它将调用 HTTP 请求来更新付款状态。

  
这样一来，编程范式发生了变化，支付服务不再需要浪费资源来轮询支付状态。

  
如果 PSP 从不回拨怎么办？我们可以设置一个家政工作，每小时检查付款状态。

  
Webhooks 通常被称为反向 API 或推送 API，因为服务器向客户端发送 HTTP 请求。在使用 webhook 时，我们需要注意 3 件事：

1.    
    我们需要为外部服务设计一个合适的 API 来调用。
2.    
    出于安全原因，我们需要在 API 网关中建立适当的规则。
3.    
    我们需要在外部服务上注册正确的 URL。

###  如何提高 API 性能？

  
下面的图表显示了 5 种常见的提高 API 性能的技巧。

![](../images/api-performance.jpg)

 分页

  
这是在结果大小较大时的常见优化。结果会以流式传输的方式返回给客户端，以提高服务的响应速度。

 异步记录

  
同步记录处理每次调用都会涉及磁盘，可能会减慢系统速度。异步记录首先将日志发送到无锁缓冲区，然后立即返回。日志将定期刷新到磁盘，这显著减少了 I/O 开销。

 缓存

  
我们可以将经常访问的数据存储到缓存中。客户端可以首先查询缓存，而不是直接访问数据库。如果缓存未命中，客户端可以从数据库查询。像 Redis 这样的缓存将数据存储在内存中，因此数据访问比数据库快得多。

 负载压缩

  
请求和响应可以使用 gzip 等进行压缩，从而传输的数据大小要小得多。这样可以加快上传和下载速度。

 连接池

  
在访问资源时，我们经常需要从数据库加载数据。打开和关闭数据库连接会增加很大的开销。因此，我们应该通过一个打开连接的连接池连接到数据库。连接池负责管理连接的生命周期。

### HTTP 1.0 -> HTTP 1.1 -> HTTP 2.0 -> HTTP 3.0 (QUIC)

  
每一代 HTTP 解决了什么问题？

  
下面的图表展示了关键特征。

![](../images/http3.jpg)

*     
    HTTP 1.0 在 1996 年最终确定并完全记录。对同一服务器的每个请求都需要单独的 TCP 连接。
    
*     
    HTTP 1.1 于 1997 年发布。TCP 连接可以保持打开以供重用（持久连接），但它并不能解决 HOL（头部阻塞）问题。
    
      
    HOL 阻塞 - 当浏览器中允许的并行请求数量用完时，后续请求需要等待前面的请求完成。
    
*     
    HTTP 2.0 于 2015 年发布。它通过请求多路复用解决了 HOL 问题，消除了应用层的 HOL 阻塞，但在传输（TCP）层仍然存在 HOL。
    
      
    正如您在图表中所看到的，HTTP 2.0 引入了 HTTP “流” 的概念：这是一种抽象，允许将不同的 HTTP 交换复用到同一个 TCP 连接上。每个流不需要按顺序发送。
    
*     
    HTTP 3.0 的首个草案于 2020 年发布。它是 HTTP 2.0 的拟定继任者。它使用 QUIC 而不是 TCP 作为底层传输协议，从而消除了传输层中的 HOL 阻塞。
    

  
QUIC 基于 UDP。它在传输层引入了流作为一等公民。QUIC 流共享相同的 QUIC 连接，因此不需要额外的握手和慢启动来创建新的流，但是 QUIC 流是独立传输的，因此在大多数情况下影响一个流的数据包丢失不会影响其他流。

### SOAP vs REST vs GraphQL vs RPC

  
下面的图表展示了 API 时间表和 API 风格的比较。

  
随着时间的推移，不同的 API 架构风格被发布。它们每个都有自己的数据交换标准化模式。

  
您可以在图表中查看每种风格的用例。

![](../images/SOAP vs REST vs GraphQL vs RPC.jpeg)

###   代码优先 vs. API 优先

  
下面的图表显示了先编码开发和先 API 开发之间的区别。为什么我们要考虑先 API 设计呢？

![](../images/api_first.jpg)

*     
    微服务增加了系统的复杂性，我们有单独的服务来提供系统的不同功能。虽然这种架构有助于解耦和职责分离，但我们需要处理各个服务之间的通信。

  
最好在编写代码之前仔细思考系统的复杂性，并仔细定义服务的边界。

*     
    独立的功能团队需要说同一种语言，专门的功能团队只负责自己的组件和服务。建议组织通过 API 设计说同一种语言。

  
我们可以模拟请求和响应来验证 API 设计是否正确，然后再编写代码。

*     
    提高软件质量和开发人员的生产力。由于我们在项目开始时已经解决了大部分不确定性，整个开发过程更加顺利，软件质量得到了极大的提升。

  
开发人员也对这个过程感到高兴，因为他们可以专注于功能开发，而不是谈判突然的变化。

  
项目生命周期末期出现意外的可能性降低了。

  
因为我们首先设计了 API，所以在开发代码的同时可以设计测试。在某种程度上，当使用 API 优先开发时，我们也在进行 TDD（测试驱动设计）。

###  HTTP 状态码

![](../images/http-status-code.jpg)

  
HTTP 的响应代码分为五类：

  
信息性（100-199）成功（200-299）重定向（300-399）客户端错误（400-499）服务器错误（500-599）

### API 网关是做什么的？

  
下面的图表显示了细节。

![](../images/api_gateway.jpg)

  
步骤 1 - 客户端向 API 网关发送 HTTP 请求。

  
第 2 步 - API 网关解析并验证 HTTP 请求中的属性。

  
第三步 - API 网关执行允许列表/拒绝列表检查。

  
第 4 步 - API 网关与身份提供者进行身份验证和授权交流。

  
第 5 步 - 速率限制规则适用于请求。如果超过限制，请求将被拒绝。

  
步骤 6 和 7 - 现在请求已经通过基本检查，API 网关通过路径匹配找到相关的服务进行路由。

  
第 8 步 - API 网关将请求转换为适当的协议，并将其发送到后端微服务。

  
步骤 9-12：API 网关可以正确处理错误，并在错误需要较长时间恢复时处理故障（断路器）。它还可以利用 ELK（Elastic-Logstash-Kibana）堆栈进行日志记录和监控。我们有时会在 API 网关中缓存数据。

### 我们如何设计有效且安全的 API？

  
下面的图表显示了带有购物车示例的典型 API 设计。

![](../images/safe-apis.jpg)

  
请注意，API 设计不仅仅是 URL 路径设计。大多数情况下，我们需要选择适当的资源名称、标识符和路径模式。同样重要的是在 API 网关内设计适当的 HTTP 标头字段或设计有效的速率限制规则。

###  TCP/IP 封装

  
数据是如何通过网络发送的？为什么 OSI 模型中需要这么多层？

  
下面的图表显示了在网络传输时数据是如何封装和解封装的。

![](../images/osi model.jpeg)

  
第一步：当设备 A 通过 HTTP 协议通过网络向设备 B 发送数据时，首先在应用层添加一个 HTTP 头。

  
第 2 步：然后在数据上添加 TCP 或 UDP 头。它在传输层被封装为 TCP 段。头部包含源端口、目的端口和序列号。

  
第三步：然后在网络层使用 IP 头对分段进行封装。IP 头包含源/目的 IP 地址。

  
第 4 步：在数据链路层为 IP 数据报添加了一个 MAC 头，带有源/目的 MAC 地址。

  
第 5 步：封装的帧被发送到物理层，并以二进制位的形式通过网络发送。

  
步骤 6-10：当设备 B 从网络接收到比特时，它执行去封装过程，这是封装过程的逆向处理。头部逐层移除，最终，设备 B 可以读取数据。

  
我们在网络模型中需要层次结构，因为每一层都专注于自己的职责。每一层可以依赖头部信息进行处理指令，而不需要了解上一层数据的含义。

### 为什么 Nginx 被称为“反向”代理？

  
下面的图表显示了一个前向协议和一个反向协议之间的区别。

![](../images/Forward Proxy v.s. Reverse Proxy2x.jpg)

  
正向代理是一台位于用户设备和互联网之间的服务器。

  
前向代理通常用于：

1.   保护客户
2.    
    规避浏览限制
3.    
    阻止访问特定内容

  
反向代理是一台服务器，它接受来自客户端的请求，将请求转发给 Web 服务器，并将结果返回给客户端，就好像代理服务器处理了该请求一样。

  
反向代理适用于：

1.   保护服务器
2.   负载均衡
3.   缓存静态内容
4.    
    加密和解密 SSL 通信

###   常见的负载均衡算法有哪些？

  
下面的图表显示了 6 种常见的算法。

![](../images/lb-algorithms.jpg)

*    静态算法

1.   轮流比赛
    
      
    客户端请求按顺序发送到不同的服务实例。通常要求服务是无状态的。
    
2.   粘性轮询
    
      
    这是轮询算法的改进。如果 Alice 的第一个请求发送到服务 A，那么接下来的请求也会发送到服务 A。
    
3.   加权轮询
    
      
    管理员可以为每个服务指定权重。具有较高权重的服务处理的请求比其他服务更多。
    
4.   哈希
    
      
    该算法对传入请求的 IP 或 URL 应用哈希函数。根据哈希函数的结果，请求被路由到相关实例。
    

*    动态算法

5.   最少连接
    
      
    将新请求发送到具有最少并发连接的服务实例。
    
6.   最短响应时间
    
      
    将新请求发送到具有最快响应时间的服务实例。
    

###   URL，URI，URN - 你知道它们之间的区别吗？

  
下面的图表显示了 URL、URI 和 URN 的比较。

![](../images/url-uri-urn.jpg)

*   URI

  
URI 代表统一资源标识符。它标识网络上的逻辑或物理资源。URL 和 URN 是 URI 的子类型。URL 定位资源，而 URN 命名资源。

  
URI 由以下部分组成：scheme:[//authority]path[?query][#fragment]

*   URL

  
URL 代表统一资源定位符，是 HTTP 的关键概念。它是网络上唯一资源的地址。它可以与其他协议一起使用，如 FTP 和 JDBC。

*   URN

  
URN 代表统一资源名称。它使用 urn 方案。 URN 无法用于定位资源。 图表中给出的一个简单示例由命名空间和特定于命名空间的字符串组成。

  
如果您想了解更多关于这个主题的细节，我建议[W3C 的澄清](https://www.w3.org/TR/uri-clarification/)。

## CI/CD

### CI/CD 管道以简单的术语解释

![](../images/ci-cd-pipeline.jpg)

  
第 1 节 - 具有 CI/CD 的 SDLC

  
软件开发生命周期（SDLC）包括几个关键阶段：开发、测试、部署和维护。CI/CD 自动化并整合这些阶段，以实现更快速和更可靠的发布。

  
当代码被推送到 git 存储库时，它会触发自动构建和测试过程。端到端（e2e）测试用例被运行以验证代码。如果测试通过，代码可以自动部署到预发布/生产环境。如果发现问题，代码将被发送回开发部门进行错误修复。这种自动化为开发人员提供了快速反馈，并减少了生产环境中出现错误的风险。

  
第 2 节 - CI 和 CD 之间的区别

  
持续集成（CI）自动化构建、测试和合并过程。每当提交代码时运行测试，以便及早发现集成问题。这鼓励频繁的代码提交和快速反馈。

  
持续交付（CD）自动化释放流程，如基础设施更改和部署。它确保软件可以通过自动化工作流在任何时候可靠地发布。CD 也可能自动化生产部署之前所需的手动测试和批准步骤。

  
第三部分 - CI/CD 管道

  
一个典型的 CI/CD 流水线具有几个连接的阶段：

*     
    开发人员向源代码控制提交代码更改
*     
    CI 服务器检测到更改并触发构建
*     
    代码已编译并测试（单元测试，集成测试）
*     
    向开发人员报告的测试结果
*     
    成功时，工件将部署到暂存环境
*     
    在发布之前可以在暂存环境上进行进一步测试
*     
    CD 系统将已批准的更改部署到生产环境

###   Netflix 技术栈（CI/CD 流水线）

![](../images/netflix-ci-cd.jpg)

  
规划：Netflix 工程部门使用 JIRA 进行规划，使用 Confluence 进行文档编写。

  
编码：Java 是后端服务的主要编程语言，而其他语言用于不同的用例。

  
构建：Gradle 主要用于构建，Gradle 插件是为了支持各种用例而构建的。

  
打包：包和依赖项被打包到一个亚马逊机器映像（AMI）中以供发布。

  
测试：测试强调了生产文化对建立混乱工具的关注。

  
部署：Netflix 使用其自建的 Spinnaker 进行金丝雀发布部署。

  
监控：监控指标集中在 Atlas 中，Kayenta 用于检测异常。

  
事件报告：根据优先级分派事件，并使用 PagerDuty 进行事件处理。

##  架构模式

### MVC，MVP，MVVM，MVVM-C 和 VIPER

  
这些架构模式是在应用程序开发中最常用的，无论是在 iOS 还是 Android 平台上。开发人员已经引入它们来克服早期模式的局限性。那么，它们有什么不同呢？

![](../images/client arch patterns.png)

*     
    MVC，最古老的模式，可以追溯到近 50 年前
*     
    每个模式都有一个“视图”（V）负责显示内容并接收用户输入
*     
    大多数模式包括一个“模型”（M）来管理业务数据
*     
    "Controller," "presenter," 和 "view-model" 是在视图和模型（在 VIPER 模式中称为 "entity"）之间进行调解的翻译器

###   18 个每个开发人员都应该了解的关键设计模式

  
模式是常见设计问题的可重用解决方案，可以使开发过程更加顺畅、高效。它们作为构建更好软件结构的蓝图。以下是一些最流行的模式：

![](../images/18-oo-patterns.png)

*     
    抽象工厂：家族创建者 - 制作相关项目组。
*     
    建造者：乐高大师 - 逐步构建物体，保持创作和外观分开。
*     
    原型：克隆制造者 - 创建完全准备好的示例的副本。
*     
    单例模式：独一无二 - 一个只有一个实例的特殊类。
*     
    适配器：通用插头 - 连接具有不同接口的设备。
*     
    桥梁：功能连接器 - 将一个对象的工作方式与其功能联系起来。
*     
    复合物：树形构建器 - 形成简单和复杂部分的树状结构。
*     
    装饰器：自定义器 - 为对象添加功能而不改变其核心。
*     
    外观：一站式购物 - 代表一个具有单一简化界面的整个系统。
*     
    轻量级：节省空间 - 高效共享小型、可重复使用的物品。
*     
    代理：替身演员 - 代表另一个对象，控制访问或操作。
*     
    责任链模式：请求中继 - 将请求通过一系列对象传递，直到被处理。
*     
    命令：任务包装器 - 将请求转换为一个准备好执行的对象。
*     
    迭代器：集合浏览器 - 逐个访问集合中的元素。
*     
    调解者：通信中心 - 简化不同类别之间的交互。
*     
    纪念品：时间胶囊 - 捕捉并恢复对象的状态。
*     
    观察者：新闻广播员 - 通知其他对象的变化。
*     
    访客：Skillful Guest - 在不改变类的情况下为其添加新操作。

## 数据库

###   云服务中不同数据库的简便备忘单

![](../images/cloud-dbs2.png)

  
为您的项目选择合适的数据库是一项复杂的任务。许多数据库选项，每个都适用于不同的用例，可能很快导致决策疲劳。

  
我们希望这份速查表能够为您提供高层次的指导，帮助您找到与项目需求相符的正确服务，并避免潜在的问题。

  
注意：Google 对其数据库用例的文档有限。尽管我们尽力查看了可用的内容并选择了最佳选项，但有些条目可能需要更准确。

###   驱动您数据库的 8 种数据结构

  
答案会根据您的用例而有所不同。数据可以在内存中或磁盘上进行索引。同样，数据格式也会有所不同，例如数字、字符串、地理坐标等。系统可能是写入密集型或读取密集型。所有这些因素都会影响您选择的数据库索引格式。

![](../images/8-ds-db.jpg)

  
以下是用于索引数据的一些最流行的数据结构：

*     
    跳表：一种常见的内存索引类型。在 Redis 中使用。
*     
    哈希索引：一种非常常见的“Map”数据结构（或“Collection”）的实现
*     
    SSTable: 不可变的磁盘上的“Map”实现
*     
    LSM 树：Skiplist + SSTable。高写入吞吐量
*     
    B-树：基于磁盘的解决方案。一致的读/写性能
*     
    倒排索引：用于文档索引。在 Lucene 中使用
*     
    后缀树：用于字符串模式搜索
*     
    R-tree：多维搜索，如查找最近邻居

###   数据库中如何执行 SQL 语句？

  
下面的图表显示了这个过程。请注意，不同数据库的架构是不同的，图表展示了一些常见的设计。

![](../images/sql execution order in db.jpeg)

  
第一步 - 通过传输层协议（例如 TCP）将 SQL 语句发送到数据库。

  
第 2 步 - SQL 语句被发送到命令解析器，经过语法和语义分析，然后生成查询树。

  
第三步 - 查询树被发送到优化器。优化器创建执行计划。

  
第 4 步 - 执行计划发送给执行者。执行者从执行中检索数据。

  
第 5 步 - 访问方法提供了执行所需的数据提取逻辑，从存储引擎中检索数据。

  
第 6 步 - 访问方法决定 SQL 语句是否为只读。如果查询是只读的（SELECT 语句），则将其传递给缓冲区管理器进行进一步处理。缓冲区管理器在缓存或数据文件中查找数据。

  
第 7 步 - 如果该语句是 UPDATE 或 INSERT，则将其传递给事务管理器进行进一步处理。

  
第 8 步 - 在交易过程中，数据处于锁定模式。这由锁管理器保证。它还确保了交易的 ACID 属性。

###  CAP 定理

  
CAP 定理是计算机科学中最著名的术语之一，但我敢打赌不同的开发人员对它有不同的理解。让我们来看看它是什么，以及为什么会令人困惑。

![](../images/cap theorem.jpeg)

  
CAP 定理指出，分布式系统无法同时提供这三个保证中的两个以上。

  
**一致性**: 一致性意味着所有客户端无论连接到哪个节点，都会在同一时间看到相同的数据。

  
**可用性**: 可用性意味着任何请求数据的客户端都会收到响应，即使其中一些节点宕机。

  
**分区容忍性**：分区表示两个节点之间的通信中断。分区容忍性意味着系统在网络分区的情况下继续运行。

  
“2 of 3” 公式可能有用，**但这种简化可能会误导**。

1.    
    选择数据库并不容易。仅仅基于 CAP 定理来证明我们的选择是不够的。例如，公司不会仅仅因为 Cassandra 是一个 AP 系统就选择它作为聊天应用程序。Cassandra 有一系列优点，使其成为存储聊天消息的理想选择。我们需要深入挖掘。
    
2.    
    “CAP 仅禁止设计空间的一小部分：在存在分区的情况下实现完美的可用性和一致性，这种情况很少见。”引自论文：CAP 十二年后： “规则”如何改变。
    
3.    
    该定理涉及 100%的可用性和一致性。更现实的讨论应该是在没有网络分区时延迟和一致性之间的权衡。有关更多详细信息，请参阅 PACELC 定理。
    

**  
CAP 定理实际上有用吗？**

  
我认为这仍然是有用的，因为它让我们对一系列权衡讨论有了开放的思路，但这只是故事的一部分。在选择正确的数据库时，我们需要深入挖掘。

###   存储器和存储类型

![](../images/Types_of_Memory_and_Storage.jpeg)

###  可视化 SQL 查询

![](../images/sql-execution-order.jpg)

  
SQL 语句由数据库系统在几个步骤中执行，包括：

*     
    解析 SQL 语句并检查其有效性
*     
    将 SQL 转换为内部表示，比如关系代数
*     
    优化内部表示并创建利用索引信息的执行计划
*     
    执行计划并返回结果

  
SQL 的执行非常复杂，涉及许多考虑因素，例如：

*     
    指数和缓存的使用
*     
    表连接的顺序
*    并发控制
*    交易管理

###  SQL 语言

  
1986 年，SQL（结构化查询语言）成为标准。在接下来的 40 年里，它成为关系数据库管理系统的主导语言。阅读最新标准（ANSI SQL 2016）可能会耗费时间。我该如何学习呢？

![](../images/how-to-learn-sql.jpg)

  
SQL 语言有 5 个组成部分：

*     
    DDL：数据定义语言，如 CREATE，ALTER，DROP
*     
    DQL：数据查询语言，例如 SELECT
*     
    DML：数据操作语言，如 INSERT，UPDATE，DELETE
*     
    DCL：数据控制语言，如 GRANT，REVOKE
*     
    TCL：事务控制语言，如 COMMIT，ROLLBACK

  
对于后端工程师来说，你可能需要了解大部分内容。作为数据分析师，你可能需要对 DQL 有很好的理解。选择与你最相关的主题。

 缓存
---

###   数据被缓存在各个地方

  
这个图表展示了在典型架构中我们缓存数据的位置。

![](../images/where do we cache data.jpeg)

  
有**多个层**沿着流动。

1.    
    客户端应用程序：HTTP 响应可以被浏览器缓存。我们首次通过 HTTP 请求数据，返回的数据中包含 HTTP 头部中的过期策略；再次请求数据时，客户端应用程序会首先尝试从浏览器缓存中检索数据。
2.    
    CDN：CDN 缓存静态网络资源。客户端可以从附近的 CDN 节点检索数据。
3.    
    负载均衡器：负载均衡器可以缓存资源。
4.    
    消息基础设施：消息代理首先将消息存储在磁盘上，然后消费者以自己的速度检索它们。根据保留策略，数据在 Kafka 集群中缓存一段时间。
5.    
    服务：服务中有多个层次的缓存。如果数据未缓存在 CPU 缓存中，服务将尝试从内存中检索数据。有时服务会有第二级缓存，用于将数据存储在磁盘上。
6.    
    分布式缓存：像 Redis 这样的分布式缓存在内存中保存多个服务的键值对。它提供比数据库更好的读写性能。
7.    
    全文搜索：我们有时需要使用全文搜索，如 Elastic Search 用于文档搜索或日志搜索。 数据的副本也被索引在搜索引擎中。
8.    
    数据库：即使在数据库中，我们也有不同级别的缓存：

*     
    WAL（预写式日志）：数据在构建 B 树索引之前首先写入 WAL
*     
    缓冲池：分配给缓存查询结果的内存区域
*     
    物化视图：预先计算查询结果并将其存储在数据库表中，以提高查询性能
*     
    事务日志：记录所有的交易和数据库更新
*     
    复制日志：用于记录数据库集群中的复制状态

###   为什么 Redis 这么快？

  
下图显示了三个主要原因。

![](../images/why_redis_fast.jpeg)

1.    
    Redis 是一种基于 RAM 的数据存储。RAM 访问速度至少比随机磁盘访问快 1000 倍。
2.    
    Redis 利用 IO 多路复用和单线程执行循环来提高执行效率。
3.    
    Redis 利用了几种高效的底层数据结构。

  
问题：另一个流行的内存存储是 Memcached。您知道 Redis 和 Memcached 之间的区别吗？

  
您可能已经注意到，这个图表的风格与我之前的帖子不同。请告诉我您更喜欢哪一个。

###   Redis 如何使用？

![](../images/top-redis-use-cases.jpg)

  
Redis 不仅仅是缓存。

  
Redis 可以在图表中显示的各种场景中使用。

*    会话
    
      
    我们可以使用 Redis 在不同服务之间共享用户会话数据。
    
*    缓存
    
      
    我们可以使用 Redis 来缓存对象或页面，特别是热点数据。
    
*    分布式锁
    
      
    我们可以使用 Redis 字符串在分布式服务之间获取锁。
    
*    柜台
    
      
    我们可以统计文章的点赞数或阅读量。
    
*    速率限制器
    
      
    我们可以为某些用户 IP 应用速率限制器。
    
*    全球 ID 生成器
    
      
    我们可以使用 Redis Int 来生成全局 ID。
    
*    购物车
    
      
    我们可以使用 Redis Hash 来表示购物车中的键值对。
    
*    计算用户留存
    
      
    我们可以使用位图来表示用户每日登录并计算用户留存。
    
*    消息队列
    
      
    我们可以使用列表作为消息队列。
    
*    排名
    
      
    我们可以使用 ZSet 来对文章进行排序。
    

###  顶级缓存策略

  
设计大规模系统通常需要仔细考虑缓存。以下是经常使用的五种缓存策略。

![](../images/top_caching_strategy.jpeg)

  
## 微服务架构

###   典型的微服务架构是什么样的？

![](../images/typical-microservice-arch.jpg)

  
下面的图表显示了典型的微服务架构。

*     
    负载均衡器：这将传入的流量分发到多个后端服务。
*     
    CDN（内容传送网络）：CDN 是一组地理分布的服务器，用于保存静态内容以实现更快的传送。客户端首先在 CDN 中查找内容，然后再转向后端服务。
*     
    API 网关：这个处理传入的请求并将它们路由到相关的服务。它与身份提供者和服务发现进行通信。
*     
    身份提供者：这负责用户的身份验证和授权。
*     
    服务注册表和发现：微服务的注册和发现发生在这个组件中，API 网关在这个组件中寻找相关服务进行通信。
*     
    管理：这个组件负责监控服务。
*     
    微服务：微服务是在不同的领域中设计和部署的。每个领域都有自己的数据库。API 网关通过 REST API 或其他协议与微服务通信，同一领域内的微服务之间使用 RPC（远程过程调用）进行通信。

  
微服务的好处：

*     
    它们可以快速设计、部署和水平扩展。
*     
    每个域名都可以由专门的团队独立维护。
*     
    业务需求可以在每个领域进行定制，并得到更好的支持。

###   微服务最佳实践

  
一图胜过千言万语：开发微服务的 9 个最佳实践。

![](../images/microservice-best-practices.jpeg)

  
当我们开发微服务时，我们需要遵循以下最佳实践：

1.    
    为每个微服务使用单独的数据存储
2.    
    保持代码在相似的成熟水平
3.    
    每个微服务单独构建
4.    
    为每个微服务分配单一责任
5.   部署到容器中
6.    
    设计无状态服务
7.    
    采用领域驱动设计
8.   设计微前端
9.    
    编排微服务

###   微服务通常使用哪种技术栈？

  
下面您将找到一个显示微服务技术栈的图表，包括开发阶段和生产阶段。

![](../images/microservice-tech.jpeg)

  
▶️ 产品推广

*     
    定义 API - 这在前端和后端之间建立了一个合同。我们可以使用 Postman 或 OpenAPI 来实现这一点。
*     
    开发 - Node.js 或 React 在前端开发中很受欢迎，而 Java/Python/Go 在后端开发中很流行。此外，我们需要根据 API 定义更改 API 网关中的配置。
*     
    持续集成 - JUnit 和 Jenkins 用于自动化测试。 代码被打包成 Docker 镜像，并部署为微服务。

 ▶️ 产品

*     
    NGinx 是负载均衡器的常见选择。Cloudflare 提供 CDN（内容传送网络）。
*     
    API 网关 - 我们可以使用 spring boot 作为网关，并使用 Eureka/Zookeeper 进行服务发现。
*     
    微服务部署在云上。我们可以选择 AWS、Microsoft Azure 或 Google GCP。缓存和全文搜索 - Redis 是缓存键值对的常见选择。Elasticsearch 用于全文搜索。
*     
    通信 - 为了让服务之间进行通信，我们可以使用消息基础设施 Kafka 或 RPC。
*     
    坚持 - 我们可以使用 MySQL 或 PostgreSQL 作为关系型数据库，使用 Amazon S3 作为对象存储。如果需要的话，我们也可以使用 Cassandra 作为宽列存储。
*     
    管理和监控 - 要管理这么多微服务，常见的运维工具包括 Prometheus、Elastic Stack 和 Kubernetes。

###  为什么 Kafka 快

  
有许多设计决策对 Kafka 的性能有所贡献。在本文中，我们将重点关注两个。我们认为这两个决策起到了最重要的作用。

![](../images/why_is_kafka_fast.jpeg)

1.    
    第一个是卡夫卡对顺序 I/O 的依赖。
2.    
    Kafka 获得性能优势的第二个设计选择是其专注于效率：零拷贝原则。

  
该图解释了数据是如何在生产者和消费者之间传输的，以及零拷贝的含义。

*     
    步骤 1.1 - 1.3：生产者将数据写入磁盘
*     
    步骤 2：消费者在没有零拷贝的情况下读取数据

  
2.1 数据从磁盘加载到操作系统缓存

  
2.2 数据从操作系统缓存复制到 Kafka 应用程序

  
2.3 Kafka 应用程序将数据复制到套接字缓冲区

  
2.4 数据从套接字缓冲区复制到网络卡

  
2.5 网卡将数据发送给消费者

*     
    第三步：消费者使用零拷贝读取数据

  
3.1：数据从磁盘加载到操作系统缓存 3.2 操作系统缓存通过 sendfile()命令直接将数据复制到网络卡 3.3 网络卡将数据发送给消费者

  
零拷贝是在应用程序上下文和内核上下文之间保存多个数据副本的快捷方式。

##  支付系统

###   如何学习支付系统？

![](../images/learn-payments.jpg)

###   为什么信用卡被称为“银行中最赚钱的产品”？VISA/Mastercard 如何赚钱？

  
下面的图表显示了信用卡支付流程的经济学。

![](../images/how does visa makes money.jpg)

  
1. 持卡人支付 100 美元给商家购买产品。

  
2. 商家通过使用信用卡获得更高的销售额，并需要向发卡行和信用卡网络支付提供支付服务的补偿。收单银行与商家设定一项费用，称为“商家折扣费”。

  
3 - 4。收单行保留 0.25 美元作为收单标记，1.75 美元支付给发卡行作为互换费。商户折扣费应该覆盖互换费。

  
互换费是由卡网络设定的，因为每家发卡银行与每家商户谈判费用效率较低。

  
5. 卡网络与每家银行建立网络评估和费用，每家银行每月向卡网络支付其服务费用。例如，VISA 每次刷卡收取 0.11%的评估费，再加上 0.0195 美元的使用费。

  
6. 持卡人向发卡银行支付其服务费。

  
为什么应该对发卡银行进行补偿？

*     
    发卡行即使持卡人未能偿还款项，也会向商家支付款项。
*     
    发卡行在持卡人支付发卡行之前支付商家。
*     
    发行人还有其他运营成本，包括管理客户账户、提供报表、欺诈检测、风险管理、结算等。

###   当我们在商家店铺刷信用卡时，VISA 是如何运作的？

![](../images/visa_payment.jpeg)

  
VISA、Mastercard 和 American Express 作为清算和结算资金的卡网络。持卡银行和发卡银行可以是不同的。如果银行要逐笔交易结算而没有中介，每家银行都必须与其他所有银行结算交易。这是相当低效的。

  
下面的图表显示了 VISA 在信用卡支付过程中的角色。涉及两个流程。授权流程发生在客户刷卡时。捕获和结算流程发生在商家想要在一天结束时拿到钱时。

*    授权流程

  
步骤 0：发卡银行向其客户发行信用卡。

  
步骤 1：持卡人想购买产品，并在商家店铺的销售点（POS）终端刷信用卡。

  
步骤 2：POS 终端将交易发送给提供 POS 终端的收单银行。

  
步骤 3 和 4：收单银行将交易发送到卡网络，也称为卡方案。卡网络将交易发送到发卡银行进行批准。

  
步骤 4.1、4.2 和 4.3：如果交易获得批准，发卡银行会冻结资金。批准或拒绝结果将发送给收单方和 POS 终端。

*     
    捕获和结算流程

  
步骤 1 和 2：商家希望在一天结束时收取款项，因此他们在 POS 终端上点击“捕获”。 交易以批量形式发送给收单方。 收单方将带有交易的批处理文件发送给卡网络。

  
第三步：卡网络对从不同收单方收集的交易进行结算，并将结算文件发送给不同的发卡银行。

  
第四步：发卡银行确认清算文件的正确性，并将资金转账给相关的收单银行。

  
第 5 步：收购银行随后将资金转账至商家的银行。

  
第四步：卡网络清理来自不同收单银行的交易。清算是一种相互抵消交易的过程，从而减少总交易数量。

  
在这个过程中，卡网络承担了与每家银行交谈的负担，并收取服务费作为回报。

###   世界各地的支付系统系列（第 1 部分）：印度的统一支付接口（UPI）

  
什么是 UPI？UPI 是由印度国家支付公司开发的即时实时支付系统。

  
它占据了印度今天数字零售交易的 60%。

  
UPI = 支付标记语言 + 互操作支付标准

![](../images/how-does-upi-work.png)

## DevOps

###   DevOps vs. SRE vs. 平台工程。有什么区别？

  
DevOps、SRE 和平台工程的概念是在不同的时间出现的，并由各种个人和组织发展起来的。

![](../images/devops-sre-platform.jpg)

  
DevOps 的概念是由 Patrick Debois 和 Andrew Shafer 在 2009 年的敏捷会议上提出的。他们试图通过促进协作文化和对整个软件开发生命周期的共同责任来弥合软件开发和运维之间的鸿沟。

  
SRE，即站点可靠性工程，是谷歌在 21 世纪初首创的，旨在解决管理大规模、复杂系统中的运营挑战。谷歌开发了 SRE 实践和工具，如 Borg 集群管理系统和 Monarch 监控系统，以提高其服务的可靠性和效率。

  
平台工程是一个较新的概念，建立在 SRE 工程的基础之上。平台工程的确切起源不太清楚，但通常被理解为 DevOps 和 SRE 实践的延伸，重点是提供一个全面的平台，支持整个业务视角的产品开发。

  
值得注意的是，尽管这些概念是在不同的时间出现的，但它们都与软件开发和运营中改进协作、自动化和效率的更广泛趋势相关。

###   k8s（Kubernetes）是什么？

  
K8s 是一个容器编排系统。它用于容器部署和管理。它的设计受到了 Google 内部系统 Borg 的极大影响。

![](../images/k8s.jpeg)

  
一个 k8s 集群由一组运行容器化应用程序的工作机器（称为节点）组成。每个集群至少有一个工作节点。

  
工作节点托管应用程序工作负载的组件 Pods。控制平面管理集群中的工作节点和 Pods。在生产环境中，控制平面通常在多台计算机上运行，并且集群通常运行多个节点，提供容错性和高可用性。

*    控制平面组件

1.   API 服务器
    
      
    API 服务器与 k8s 集群中的所有组件进行通信。通过与 API 服务器交谈，对 Pod 上的所有操作都会被执行。
    
2.   调度程序
    
      
    调度程序监视 Pod 工作负载，并将负载分配给新创建的 Pod。
    
3.   控制器管理器
    
      
    控制器管理器运行控制器，包括节点控制器、作业控制器、端点切片控制器和服务账户控制器。
    
4.  Etcd
    
      
    etcd 是一个键值存储，用作 Kubernetes 的后备存储，用于存储所有集群数据。
    

*    节点

1.   豆荚
    
      
    Pod 是一组容器，是 k8s 管理的最小单元。Pod 具有一个单一的 IP 地址，应用于 Pod 内的每个容器。
    
2.  Kubelet
    
      
    在集群中的每个节点上运行的代理。它确保 Pod 中的容器正在运行。
    
3.   Kube 代理
    
      
    Kube-proxy 是在集群中每个节点上运行的网络代理。它将进入节点的流量路由到服务。它将工作请求转发到正确的容器。
    

###   Docker vs. Kubernetes. 我们应该使用哪一个？

![](../images/docker-vs-k8s.jpg)

 Docker 是什么？

  
Docker 是一个开源平台，允许您将应用程序打包、分发和在隔离的容器中运行。它专注于容器化，提供轻量级环境，封装应用程序及其依赖关系。

 Kubernetes 是什么？

  
Kubernetes，通常被称为 K8s，是一个开源的容器编排平台。它提供了一个框架，用于自动化部署、扩展和管理跨节点集群中的容器化应用程序。

  
它们两者之间有什么不同？

  
Docker：Docker 在单个操作系统主机上的个别容器级别运行。

  
您必须手动管理每个主机，并为多个相关容器设置网络、安全策略和存储可能会很复杂。

  
Kubernetes：Kubernetes 在集群级别运行。它管理多个容器化应用程序跨多个主机，为诸如负载平衡、扩展和确保应用程序期望状态的任务提供自动化。

  
简而言之，Docker 专注于容器化和在单个主机上运行容器，而 Kubernetes 专注于在整个主机集群中管理和编排容器。

###  Docker 是如何工作的？

  
下面的图表显示了 Docker 的架构以及在运行“docker build”、“docker pull”和“docker run”时的工作原理。

![](../images/docker.jpg)

  
Docker 架构中有 3 个组件：

*    Docker 客户端
    
      
    Docker 客户端与 Docker 守护程序通信。
    
*    Docker 主机
    
      
    Docker 守护程序监听 Docker API 请求并管理 Docker 对象，如镜像、容器、网络和卷。
    
*    Docker 注册表
    
      
    一个 Docker 注册表存储 Docker 镜像。Docker Hub 是一个任何人都可以使用的公共注册表。
    

  
让我们以“docker run”命令为例。

1.    
    Docker 从注册表中拉取镜像。
2.    
    Docker 创建一个新的容器。
3.    
    Docker 为容器分配读写文件系统。
4.    
    Docker 创建一个网络接口，将容器连接到默认网络。
5.    
    Docker 启动容器。

GIT
---

###  Git 命令如何工作

  
首先，必须确定我们的代码存储在哪里。通常的假设是只有两个位置 - 一个在像 Github 这样的远程服务器上，另一个在我们的本地机器上。然而，这并不完全准确。Git 在我们的机器上维护了三个本地存储位置，这意味着我们的代码可以在四个地方找到：

![](../images/git-commands.png)

*     
    工作目录：我们编辑文件的地方
*     
    暂存区：文件被保存以供下一次提交的临时位置
*     
    本地存储库：包含已提交的代码
*     
    远程存储库：存储代码的远程服务器

  
大多数 Git 命令主要在这四个位置之间移动文件。

###  Git 是如何工作的？

  
下面的图表显示了 Git 工作流程。

![](../images/git-workflow.jpeg)

  
Git 是一个分布式版本控制系统。

  
每个开发人员都维护着主代码库的本地副本，并对本地副本进行编辑和提交。

  
提交非常快，因为操作不与远程存储库交互。

  
如果远程存储库崩溃，文件可以从本地存储库恢复。

###   Git 合并 vs. Git 变基

  
什么是不同之处？

![](../images/git-merge-git-rebase.jpeg)

  
当我们从一个 Git 分支合并更改到另一个分支时，我们可以使用'git merge'或'git rebase'。下面的图表显示了这两个命令的工作原理。

 **Git 合并**

  
这在主分支中创建了一个新的提交 G’。G’ 将主分支和特性分支的历史联系在一起。

  
Git 合并是**非破坏性**。主分支和特性分支都不会被更改。

**Git rebase**

  
Git rebase 将特性分支历史记录移动到主分支的头部。它为特性分支中的每个提交创建新的提交 E'、F'和 G'。

  
重置基础的好处在于它具有线性的**提交历史**。

  
如果不遵循“git rebase 的黄金法则”，rebase 可能会很危险。

**  
Git Rebase 的黄金法则**

  
永远不要在公共分支上使用它！

 云服务
----

###   不同云服务的简便备忘单（2023 版）

![](../images/cloud-compare.jpg)

###  什么是云原生？

  
以下是自 1980 年代以来建筑和流程演变的图表。

![](../images/cloud-native.jpeg)

  
组织可以利用云原生技术在公共、私有和混合云上构建和运行可扩展的应用程序。

  
这意味着这些应用程序旨在利用云功能，因此它们对负载具有弹性且易于扩展。

  
云原生包括 4 个方面：

1.   发展过程
    
      
    这已经从瀑布模型进化到敏捷开发，再到 DevOps。
    
2.   应用架构
    
      
    架构已经从单片到微服务。每个服务都设计为小型，适应云容器中有限的资源。
    
3.   部署和打包
    
      
    应用程序过去部署在物理服务器上。然后大约在 2000 年左右，那些不太敏感于延迟的应用程序通常部署在虚拟服务器上。有了云原生应用程序，它们被打包成 Docker 镜像并部署在容器中。
    
4.    
    应用基础设施
    
      
    应用程序大规模部署在云基础设施上，而不是自托管服务器上。
    

  
## 开发者生产力工具

###  可视化 JSON 文件

  
嵌套的 JSON 文件很难阅读。

  
**JsonCrack** 从 JSON 文件生成图形图表，并使其易于阅读。

  
此外，生成的图表可以下载为图片。

![](../images/json-cracker.jpeg)

###   自动将代码转换为架构图

![](../images/diagrams_as_code.jpeg)

 它是做什么的？

*     
    用 Python 代码绘制云系统架构。
*     
    图表也可以直接在 Jupyter 笔记本中呈现。
*     
    不需要设计工具。
*     
    支持以下提供商：AWS，Azure，GCP，Kubernetes，阿里云，Oracle Cloud 等。

 [Github 仓库](https://github.com/mingrammer/diagrams)

## Linux

###   Linux 文件系统解释

![](../images/linux-file-systems.jpg)

  
Linux 文件系统曾经类似于一个无组织的城镇，个人可以随意在任何地方建造他们的房屋。然而，1994 年引入了文件系统层次结构标准（FHS），以整顿 Linux 文件系统。

  
通过实施像 FHS 这样的标准，软件可以确保在各种 Linux 发行版中保持一致的布局。然而，并非所有 Linux 发行版严格遵循这一标准。它们经常会融入自己独特的元素或迎合特定需求。要精通这一标准，您可以从探索开始。利用诸如“cd”用于导航和“ls”用于列出目录内容的命令。将文件系统想象成一棵树，从根目录（/）开始。随着时间的推移，这将变得自然而然，将您转变为一名熟练的 Linux 管理员。

###   18 个你应该知道的最常用的 Linux 命令

  
Linux 命令是与操作系统交互的指令。它们帮助管理文件、目录、系统进程以及系统的许多其他方面。为了有效地浏览和维护基于 Linux 的系统，您需要熟悉这些命令。

  
下面的图表显示了流行的 Linux 命令：

![](../images/18 Most-Used Linux Commands You Should Know-01.jpeg)

*     
    ls - 列出文件和目录
*     
    cd - 更改当前目录
*     
    创建一个新目录
*     
    rm - 删除文件或目录
*     
    cp - 复制文件或目录
*     
    mv - 移动或重命名文件或目录
*     
    chmod - 更改文件或目录权限
*     
    grep - 在文件中搜索模式
*     
    查找 - 搜索文件和目录
*     
    tar - 操作 tarball 存档文件
*     
    vi - 使用文本编辑器编辑文件
*     
    猫 - 显示文件内容
*     
    顶部 - 显示进程和资源使用
*     
    ps - 显示进程信息
*     
    杀死 - 通过发送信号终止进程
*     
    du - 估算文件空间使用量
*     
    ifconfig - 配置网络接口
*     
    ping - 测试主机之间的网络连接

 安全
---

###  HTTPS 是如何工作的？

  
超文本传输安全协议（HTTPS）是超文本传输协议（HTTP）的扩展。HTTPS 使用传输层安全性（TLS）传输加密数据。如果数据在网上被劫持，劫持者只能获得二进制代码。

![](../images/https.jpg)

  
数据是如何加密和解密的？

  
第一步 - 客户端（浏览器）和服务器建立 TCP 连接。

  
第 2 步 - 客户端向服务器发送“客户端 hello”。 该消息包含一组必要的加密算法（密码套件）和它可以支持的最新 TLS 版本。 服务器以“服务器 hello”作出响应，以便浏览器知道它是否可以支持这些算法和 TLS 版本。

  
服务器然后将 SSL 证书发送给客户端。证书包含公钥、主机名、到期日期等信息。客户端验证证书。

  
第三步 - 在验证 SSL 证书后，客户端生成一个会话密钥并使用公钥对其进行加密。服务器接收加密的会话密钥并使用私钥解密。

  
第 4 步 - 现在客户端和服务器都持有相同的会话密钥（对称加密），加密数据通过安全的双向通道传输。

  
为什么 HTTPS 在数据传输过程中会切换到对称加密？主要有两个原因：

1.    
    安全性：非对称加密只能单向进行。这意味着如果服务器尝试将加密数据发送回客户端，任何人都可以使用公钥解密数据。
    
2.    
    服务器资源：非对称加密增加了相当多的数学开销。它不适用于长时间会话中的数据传输。
    

###   使用简单术语解释的 Oauth 2.0。

  
OAuth 2.0 是一个强大且安全的框架，允许不同的应用程序代表用户安全地相互交互，而无需共享敏感凭据。

![](../images/oAuth2.jpg)

  
OAuth 涉及的实体是用户、服务器和身份提供者（IDP）。

  
OAuth 令牌可以做什么？

  
当您使用 OAuth 时，您会获得一个代表您身份和权限的 OAuth 令牌。这个令牌可以做一些重要的事情：

  
单点登录（SSO）：使用 OAuth 令牌，您可以仅使用一个登录即可登录多个服务或应用程序，使生活更加简单和安全。

  
系统间授权：OAuth 令牌允许您在各个系统之间共享授权或访问权限，这样您就不必到处单独登录。

  
访问用户资料：具有 OAuth 令牌的应用程序可以访问您允许的用户资料的某些部分，但它们不会看到所有内容。

  
请记住，OAuth 2.0 的目的是在确保您和您的数据安全的同时，使您在不同的应用程序和服务之间的在线体验变得无缝和无忧。

###   认证机制的前 4 种形式

![](../images/top4-most-used-auth.jpg)

1.   SSH 密钥：
    
      
    加密密钥用于安全访问远程系统和服务器
    
2.   OAuth 令牌:
    
      
    提供对第三方应用程序上用户数据有限访问权限的令牌
    
3.   SSL 证书:
    
      
    数字证书确保服务器和客户端之间的安全和加密通信
    
4.   凭证：
    
      
    用户认证信息用于验证和授予对各种系统和服务的访问权限
    

###   会话、cookie、JWT、令牌、SSO 和 OAuth 2.0 - 它们是什么？

  
这些术语都与用户身份管理有关。当您登录网站时，您会声明自己是谁（身份验证）。您的身份会得到验证（认证），并且您将被授予必要的权限（授权）。过去已经提出了许多解决方案，而且这个列表还在不断增长。

![](../images/session.jpeg)

  
从简单到复杂，这是我对用户身份管理的理解：

*     
    WWW-Authenticate 是最基本的方法。浏览器会要求您输入用户名和密码。由于无法控制登录生命周期，因此如今很少使用。
    
*     
    对登录生命周期的更精细控制是会话 cookie。服务器维护会话存储，浏览器保留会话的 ID。Cookie 通常只适用于浏览器，不适用于移动应用程序友好。
    
*     
    为了解决兼容性问题，可以使用令牌。客户端将令牌发送到服务器，服务器验证令牌。缺点是令牌需要加密和解密，这可能会耗费时间。
    
*     
    JWT 是表示令牌的标准方式。这些信息可以得到验证和信任，因为它们是数字签名的。由于 JWT 包含签名，因此无需在服务器端保存会话信息。
    
*     
    通过使用 SSO（单一登录），您只需登录一次即可登录多个网站。它使用 CAS（中央认证服务）来维护跨站点信息。
    
*     
    通过使用 OAuth 2.0，您可以授权一个网站访问另一个网站上的信息。
    

###   如何在数据库中安全存储密码以及如何验证密码？

![](../images/salt.jpg)

 **不要做的事情**

*     
    将密码以明文形式存储并不是一个好主意，因为任何具有内部访问权限的人都可以看到它们。
    
*     
    直接存储密码哈希值是不够的，因为容易受到预计算攻击的影响，比如彩虹表。
    
*     
    为了减轻预计算攻击，我们对密码进行加盐。
    

 **什么是盐？**

  
根据 OWASP 指南，“盐是一个唯一的、随机生成的字符串，它作为哈希过程的一部分添加到每个密码中”。

**  
如何存储密码和盐？**

1.    
    哈希结果对于每个密码是唯一的。
2.    
    密码可以使用以下格式存储在数据库中：hash(password + salt)。

**  
如何验证密码？**

  
验证密码时，可以通过以下过程进行：

1.    
    客户输入密码。
2.    
    系统从数据库中获取相应的盐。
3.    
    系统将盐附加到密码并对其进行哈希处理。让我们将哈希值称为 H1。
4.    
    系统比较 H1 和 H2，其中 H2 是存储在数据库中的哈希值。如果它们相同，则密码有效。

###   向一个 10 岁的孩子解释 JSON Web Token（JWT）

![](../images/jwt.jpg)

  
想象一下，您有一个名为 JWT 的特殊盒子。在这个盒子里，有三个部分：一个头部、一个有效载荷和一个签名。

  
标题就像盒子外面的标签。它告诉我们这是什么类型的盒子以及它是如何被保护的。通常以一种称为 JSON 的格式编写，这只是一种使用花括号 { } 和冒号 : 来组织信息的方式。

  
有效载荷就像您想要发送的实际消息或信息。它可以是您的姓名、年龄或任何其他您想要分享的数据。它也以 JSON 格式编写，因此易于理解和处理。现在，签名是使 JWT 安全的关键。它就像一个特殊的印章，只有发送者知道如何创建。签名是使用秘密代码创建的，有点像密码。这个签名确保没有人可以在发送者不知情的情况下篡改 JWT 的内容。

  
当您想要将 JWT 发送到服务器时，您将头部、负载和签名放入盒子中。然后将其发送到服务器。服务器可以轻松地读取头部和负载，以了解您是谁以及您想要做什么。

###   Google Authenticator（或其他类型的双因素认证器）是如何工作的？

  
Google Authenticator 通常用于在启用两步验证时登录我们的帐户。它如何保证安全？

  
Google Authenticator 是一种基于软件的身份验证器，实现了两步验证服务。下面的图表提供了详细信息。

![](../images/google_authenticate.jpeg)

  
有两个阶段涉及：

*     
    阶段 1 - 用户启用谷歌两步验证。
*     
    阶段 2 - 用户使用身份验证器进行登录等操作。

  
让我们来看看这些阶段。

 **阶段 1**

  
步骤 1 和 2：Bob 打开网页以启用两步验证。前端请求一个秘钥。认证服务为 Bob 生成秘钥并将其存储在数据库中。

  
第三步：认证服务返回一个 URI 给前端。该 URI 由密钥发行者、用户名和秘钥组成。该 URI 以 QR 码的形式显示在网页上。

  
第四步：Bob 然后使用 Google Authenticator 扫描生成的 QR 码。密钥存储在验证器中。

  
**第 2 阶段** 步骤 1 和 2：Bob 想要使用 Google 两步验证登录网站。为此，他需要密码。每 30 秒，Google Authenticator 使用 TOTP（基于时间的一次性密码）算法生成一个 6 位数密码。Bob 使用密码进入网站。

  
步骤 3 和 4：前端将 Bob 输入的密码发送到后端进行身份验证。身份验证服务从数据库中读取密钥，并使用与客户端相同的 TOTP 算法生成一个 6 位密码。

  
第 5 步：认证服务比较客户端和服务器生成的两个密码，并将比较结果返回给前端。只有当这两个密码匹配时，Bob 才能继续登录过程。

  
这个认证机制安全吗？

*     
    其他人能获取到秘钥吗？
    
      
    我们需要确保使用 HTTPS 传输密钥。认证客户端和数据库存储密钥，我们需要确保密钥被加密。
    
*     
    黑客能猜到 6 位密码吗？
    
      
    不。密码有 6 位数字，因此生成的密码有 100 万种可能的组合。另外，密码每 30 秒更改一次。如果黑客想在 30 秒内猜出密码，他们需要每秒输入 30,000 种组合。
    

##  真实案例研究

###  Netflix 的技术堆栈

  
这篇帖子基于许多 Netflix 工程博客和开源项目的研究。如果您发现任何不准确之处，请随时告诉我们。

![](../images/netflix tech stack.png)

  
**移动和网络**：Netflix 已经采用 Swift 和 Kotlin 来构建原生移动应用。对于其 Web 应用程序，它使用 React。

  
**前端/服务器通信**：Netflix 使用 GraphQL。

  
**后端服务**：Netflix 依赖 ZUUL、Eureka、Spring Boot 框架和其他技术。

  
**数据库**：Netflix 使用 EV 缓存、Cassandra、CockroachDB 等数据库。

  
**消息传递/流媒体**: Netflix 使用 Apache Kafka 和 Fink 进行消息传递和流媒体。

  
**视频存储**：Netflix 使用 S3 和 Open Connect 进行视频存储。

  
**数据处理**: Netflix 利用 Flink 和 Spark 进行数据处理，然后使用 Tableau 进行可视化。Redshift 用于处理结构化数据仓库信息。

  
**CI/CD**: Netflix 使用各种工具，如 JIRA、Confluence、PagerDuty、Jenkins、Gradle、Chaos Monkey、Spinnaker、Atlas 等，用于 CI/CD 过程。

###   Twitter 架构 2022

  
是的，这是真正的 Twitter 架构。这是由埃隆·马斯克发布的，并由我们重新绘制以便更易阅读。

![](../images/twitter-arch.jpeg)

###   Airbnb 过去 15 年微服务架构的演变

  
Airbnb 的微服务架构经历了 3 个主要阶段。

![](../images/airbnb_arch.jpeg)

 单体（2008 年至 2017 年）

  
Airbnb 最初是一个简单的房东和客人市场。这是建立在 Ruby on Rails 应用程序中的单体。

 挑战是什么？

*     
    团队所有权混乱 + 未拥有的代码
*    部署缓慢

  
微服务（2017 年至 2020 年）

  
微服务旨在解决这些挑战。在微服务架构中，关键服务包括：

*    数据获取服务
*     
    业务逻辑数据服务
*    编写工作流服务
*    UI 聚合服务
*     
    每项服务都有一个负责团队

 挑战是什么？

  
数百种服务和依赖关系对人类来说很难管理。

  
微服务 + 宏服务（2020 年至今）

  
这是 Airbnb 目前正在努力的方向。微服务和宏服务混合模型专注于 API 的统一化。

###  单一代码库 vs. 微代码库。

  
哪个是最好的？为什么不同的公司选择不同的选项？

![](../images/monorepo-microrepo.jpg)

  
Monorepo 并不是什么新鲜事；Linux 和 Windows 都是使用 Monorepo 创建的。为了提高可扩展性和构建速度，谷歌开发了内部专用工具链，以加快扩展速度，并制定了严格的编码质量标准以保持一致性。

  
亚马逊和 Netflix 是微服务理念的主要倡导者。这种方法自然地将服务代码分开存放在不同的代码库中。它能更快地扩展，但后期可能会导致治理痛点。

  
在 Monorepo 中，每个服务都是一个文件夹，每个文件夹都有一个 BUILD 配置和 OWNERS 权限控制。每个服务成员都负责自己的文件夹。

  
另一方面，在 Microrepo 中，每个服务都负责其存储库，通常为整个存储库设置构建配置和权限。

  
在 Monorepo 中，无论您的业务如何，依赖项都在整个代码库中共享，因此当有版本升级时，每个代码库都会升级其版本。

  
在 Microrepo 中，依赖关系在每个存储库内进行控制。企业根据自己的时间表选择何时升级版本。

  
Monorepo 有一个标准的签入流程。Google 的代码审查流程以设定高标准而闻名，确保 Monorepo 的一致质量标准，无论业务如何。

  
Microrepo 可以自行制定标准，也可以通过整合最佳实践来采用共享标准。它可以更快地为业务扩展，但代码质量可能会有所不同。谷歌工程师构建了 Bazel，Meta 构建了 Buck。还有其他开源工具可用，包括 Nx、Lerna 等。

  
多年来，Microrepo 拥有更多支持的工具，包括 Maven 和 Gradle 用于 Java，NPM 用于 NodeJS，以及 CMake 用于 C/C++等。

###   你将如何设计 Stack Overflow 网站？

  
如果您的答案是本地服务器和单体（在下图底部），您很可能会在面试中失败，但这就是现实中的情况！

![](../images/stackoverflow.jpg)

**  
人们认为它应该是什么样子**

  
面试官可能期望看到图片的顶部部分。

*     
    微服务用于将系统分解为小组件。
*     
    每个服务都有自己的数据库。大量使用缓存。
*    服务已分片。
*     
    服务通过消息队列异步地相互通信。
*     
    该服务使用事件溯源和 CQRS 实现。
*     
    展示在分布式系统中的知识，比如最终一致性、CAP 理论等。

 **它实际上是什么**

  
Stack Overflow 仅使用 9 台本地 Web 服务器处理所有流量，并且它是单体架构！它拥有自己的服务器，不在云上运行。

  
这与我们当今所有流行的信念相悖。

###   亚马逊 Prime Video 监控为什么从无服务器转向单体？如何能节省 90%的成本？

  
下面的图表显示了迁移前后的架构比较。

![](../images/serverless-to-monolithic.jpeg)

  
亚马逊 Prime Video 监控服务是什么？

  
Prime Video 服务需要监控数千个直播流的质量。监控工具会实时自动分析流，并识别像块损坏、视频冻结和同步问题等质量问题。这是客户满意度的重要过程。

  
有 3 个步骤：媒体转换器、缺陷检测器和实时通知。

*     
    旧建筑的问题是什么？
    
      
    旧架构基于亚马逊 Lambda，适用于快速构建服务。然而，在高规模运行架构时并不划算。最昂贵的两个操作是：
    

1.    
    编排工作流程 - AWS 步骤函数通过状态转换向用户收费，编排每秒执行多个状态转换。
    
2.    
    数据在分布式组件之间传递 - 中间数据存储在 Amazon S3 中，以便下一阶段可以下载。当数据量较大时，下载可能会很昂贵。
    

*     
    单体架构节省 90%的成本
    
      
    单体架构旨在解决成本问题。仍然有 3 个组件，但媒体转换器和缺陷检测器部署在同一流程中，节省了通过网络传输数据的成本。令人惊讶的是，这种部署架构变更的方法导致了 90%的成本节约！
    

  
这是一个有趣且独特的案例研究，因为微服务已经成为科技行业中的首选和时尚选择。很高兴看到我们正在更多地讨论架构的演变，并就其优缺点进行更诚实的讨论。将组件分解为分布式微服务是有成本的。

*     
    亚马逊的领导人对此有何看法？
    
      
    亚马逊首席技术官 Werner Vogels：“构建可演进的软件系统是一种策略，而不是一种宗教。以开放的心态重新审视您的架构是必不可少的。”
    

  
前亚马逊副总裁可持续发展 Adrian Cockcroft：“Prime Video 团队已经走过了我称之为**无服务器优先**的道路……我不主张**仅限无服务器**”。

###   迪士尼热星在比赛期间如何捕捉 50 亿个表情符号？

![](../images/hotstar_emojis.jpeg)

1.    
    客户端通过标准的 HTTP 请求发送表情符号。您可以将 Golang 服务视为典型的 Web 服务器。选择 Golang 是因为它很好地支持并发。Golang 中的线程是轻量级的。
    
2.    
    由于写入量很高，Kafka（消息队列）被用作缓冲区。
    
3.    
    表情符号数据由一个名为 Spark 的流处理服务聚合。它每 2 秒聚合一次数据，这是可配置的。根据间隔需要做出权衡。较短的间隔意味着表情符号会更快地传递给其他客户端，但也意味着需要更多的计算资源。
    
4.    
    聚合数据被写入另一个 Kafka。
    
5.    
    PubSub 消费者从 Kafka 拉取聚合的表情数据。
    
6.    
    表情符号通过 PubSub 基础架构实时传递到其他客户端。 PubSub 基础架构很有趣。 Hotstar 考虑了以下协议：Socketio、NATS、MQTT 和 gRPC，并最终选择了 MQTT。
    

  
LinkedIn 采用了类似的设计，每秒流量达到一百万个赞。

###   Discord 如何存储数万亿条消息

  
下面的图表显示了 Discord 消息存储的演变：

![](../images/discord-store-messages.jpg)

MongoDB ➡️ Cassandra ➡️ ScyllaDB

  
2015 年，Discord 的第一个版本是建立在单个 MongoDB 副本之上的。到了 2015 年 11 月左右，MongoDB 存储了 1 亿条消息，RAM 无法再容纳数据和索引。延迟变得不可预测。消息存储需要迁移到另一个数据库。选择了 Cassandra。

  
2017 年，Discord 有 12 个 Cassandra 节点，存储了数十亿条消息。

  
2022 年初，它有 177 个节点，传输了数万亿条消息。此时，延迟是不可预测的，维护操作变得太昂贵而无法运行。

  
问题存在几个原因：

*     
    Cassandra 使用 LSM 树作为内部数据结构。 读取比写入更昂贵。 在具有数百用户的服务器上可能会有许多并发读取，导致热点。
*     
    维护集群，如压缩 SSTables，会影响性能。
*     
    垃圾收集暂停会导致显著的延迟峰值

  
ScyllaDB 是用 C++编写的与 Cassandra 兼容的数据库。Discord 重新设计了其架构，拥有一个单体 API，一个用 Rust 编写的数据服务，以及基于 ScyllaDB 的存储。

  
ScyllaDB 中的 p99 读取延迟为 15 毫秒，而 Cassandra 中为 40-125 毫秒。p99 写入延迟为 5 毫秒，而 Cassandra 中为 5-70 毫秒。

###   YouTube、TikTok 直播或 Twitch 上的视频直播是如何运作的？

  
直播流与常规流媒体不同，因为视频内容是通过互联网实时发送的，通常延迟仅为几秒钟。

  
下面的图表解释了幕后发生的事情，使这一切成为可能。

![](../images/live_streaming_updated.jpg)

  
第一步：原始视频数据由麦克风和摄像头捕获。数据被发送到服务器端。

  
第 2 步：视频数据被压缩和编码。例如，压缩算法将背景和其他视频元素分开。压缩后，视频被编码为诸如 H.264 之类的标准。在这一步之后，视频数据的大小要小得多。

  
第三步：编码数据被分成较小的片段，通常以秒为单位，因此下载或流媒体所需的时间大大缩短。

  
第四步：分段数据被发送到流媒体服务器。流媒体服务器需要支持不同的设备和网络条件。这被称为“自适应比特率流媒体”。这意味着我们需要在第 2 步和第 3 步中以不同比特率生成多个文件。

  
第 5 步：直播流数据被推送到由 CDN（内容传送网络）支持的边缘服务器。数百万观众可以从附近的边缘服务器观看视频。CDN 显著降低数据传输延迟。

  
第 6 步：观众的设备解码和解压视频数据，并在视频播放器中播放视频。

  
步骤 7 和 8：如果视频需要存储以供重播，编码数据将被发送到存储服务器，观众可以随后从中请求重播。

  
直播的标准协议包括：

*     
    RTMP（Real-Time Messaging Protocol）：最初由 Macromedia 开发，用于在 Flash 播放器和服务器之间传输数据。现在它被用于在互联网上流式传输视频数据。请注意，视频会议应用程序如 Skype 使用 RTC（实时通信）协议以实现更低的延迟。
*     
    HLS（HTTP Live Streaming）：它需要 H.264 或 H.265 编码。苹果设备仅接受 HLS 格式。
*     
    DASH（Dynamic Adaptive Streaming over HTTP）：DASH 不支持苹果设备。
*     
    HLS 和 DASH 都支持自适应比特率流媒体。

 许可
---

  
这项工作受[CC BY-NC-ND 4.0 ![](https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1) ![](https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1) ![](https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1) ![](https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1)](http://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1)     许可。

@media (prefers-color-scheme: dark) { body { color: #fff !important; background-color: #272727 !important; } }